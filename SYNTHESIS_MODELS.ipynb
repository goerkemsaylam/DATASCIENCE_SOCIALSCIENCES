{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FBycT31faBOB",
        "Qm4rFQFOTABT",
        "xegMaAAwoyPS",
        "KPrqkyAsTPzk",
        "W6c5mzjITHA0",
        "dRNgot1nTVB8",
        "b-og4_4dTl9L",
        "4mftWfrhw7Rr",
        "5VOfNzdwaCzB",
        "5syQMGAPzTLQ",
        "lbE17TiKzT6H"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MODELS"
      ],
      "metadata": {
        "id": "FBycT31faBOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELS FOR PREDICTION"
      ],
      "metadata": {
        "id": "Qm4rFQFOTABT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Linear Regression Model"
      ],
      "metadata": {
        "id": "xegMaAAwoyPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model\n",
        "\n",
        "Simple linear regression model is:\n",
        "\n",
        "$$\n",
        "y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $y_i$: dependent variable (outcome) for observation $i$  \n",
        "- $x_i$: independent variable (predictor) for observation $i$  \n",
        "- $\\beta_0$: intercept (value of $y$ when $x=0$)  \n",
        "- $\\beta_1$: slope (change in $y$ for a one-unit increase in $x$)  \n",
        "- $\\varepsilon_i$: error term for observation $i$, assumed to have mean 0\n",
        "\n",
        "**While:**\n",
        "\n",
        "- **Known (from the data):** $x_i, y_i$ (the observations, given in the dataset).  \n",
        "- **Unknown but to be estimated:** $\\beta_0, \\beta_1$ (parameters of the regression model).  \n",
        "- **Not directly known but assumed:** $\\varepsilon_i$ (error terms, assumed to have mean 0 and constant variance).\n",
        "\n",
        "In regression, the **Residual Sum of Squares (RSS)** measures the total squared difference between the observed values $y_i$ and the predicted values $\\hat{y}_i$:\n",
        "\n",
        "$$\n",
        "RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "- $y_i$ is the observed value for observation $i$.  \n",
        "- $\\hat{y}_i$ is the predicted value from the regression model: $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$.  \n",
        "- The difference $e_i = y_i - \\hat{y}_i$ is called the residual.  \n",
        "\n",
        "To calculate $\\beta_0, \\beta_1$ to construct the model via **Ordinary Least Squares (OLS)** by minimizing the RSS:\n",
        "\n",
        "$$\n",
        "RSS(\\beta_0, \\beta_1) = \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 x_i))^2\n",
        "$$\n",
        "\n",
        "- The residual for observation $i$ is $e_i = y_i - \\hat{y}_i$.  \n",
        "- Minimizing $RSS$ gives the “best-fitting line” through the data points.\n",
        "\n",
        "#### Weighting\n",
        "\n",
        "Weighting is used when some observations are more important or more reliable than others.\n",
        "\n",
        "Weighted simple linear regression model is:\n",
        "\n",
        "$$\n",
        "y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i, \\quad i = 1,2,\\dots,n\n",
        "$$\n",
        "\n",
        "- Standard regression minimizes the Residual Sum of Squares (RSS):\n",
        "\n",
        "$$\n",
        "RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "- Weighted regression introduces weights $w_i > 0$ for each observation:\n",
        "\n",
        "$$\n",
        "WRSS = \\sum_{i=1}^n w_i \\left(y_i - \\hat{y}_i\\right)^2\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $w_i$: weight for observation $i$  \n",
        "- $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$  \n",
        "\n",
        "Minimize $WRSS$ with respect to $\\beta_0$ and $\\beta_1$:\n",
        "\n",
        "$$\n",
        "(\\hat{\\beta}_0, \\hat{\\beta}_1) = \\arg\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^n w_i (y_i - \\beta_0 - \\beta_1 x_i)^2\n",
        "$$\n",
        "\n",
        "The weighted formulas for the coefficients:\n",
        "\n",
        "$$\n",
        "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n w_i (x_i - \\bar{x}_w)(y_i - \\bar{y}_w)}{\\sum_{i=1}^n w_i (x_i - \\bar{x}_w)^2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\beta}_0 = \\bar{y}_w - \\hat{\\beta}_1 \\bar{x}_w\n",
        "$$\n",
        "\n",
        "where weighted means are:\n",
        "\n",
        "$$\n",
        "\\bar{x}_w = \\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}, \\quad\n",
        "\\bar{y}_w = \\frac{\\sum_{i=1}^n w_i y_i}{\\sum_{i=1}^n w_i}\n",
        "$$\n",
        "\n",
        "Observations with larger weights $w_i$ have more influence on the fitted line to reduce the impact of less reliable points on the coefficient estimates.\n",
        "\n",
        "#### Performance\n",
        "\n",
        "**Cross-Validation**\n",
        "\n",
        "To estimate the generalization performance of the regression model on unseen data.  \n",
        "\n",
        "**k-Fold Cross-Validation**\n",
        "\n",
        "1. Split the data into $k$ roughly equal folds (subsets): $D_1, D_2, \\dots, D_k$.  \n",
        "2. For each fold $j = 1, \\dots, k$:\n",
        "   - Train the model on the remaining $k-1$ folds: $D_{-j} = D \\setminus D_j$  \n",
        "   - Fit the model to obtain $\\hat{\\beta}_0^{(-j)}, \\hat{\\beta}_1^{(-j)}$  \n",
        "   - Predict on the left-out fold $D_j$: $\\hat{y}_i^{(-j)} = \\hat{\\beta}_0^{(-j)} + \\hat{\\beta}_1^{(-j)} x_i$ for $i \\in D_j$  \n",
        "3. Compute the prediction error (e.g., Mean Squared Error) for each fold:\n",
        "\n",
        "$$\n",
        "MSE_j = \\frac{1}{|D_j|} \\sum_{i \\in D_j} \\left(y_i - \\hat{y}_i^{(-j)}\\right)^2\n",
        "$$\n",
        "\n",
        "4. Average over all folds to get cross-validated MSE:\n",
        "\n",
        "$$\n",
        "CV_{MSE} = \\frac{1}{k} \\sum_{j=1}^{k} MSE_j\n",
        "$$\n",
        "\n",
        "- *Common choices are $k=5$ or $k=10$*  \n",
        "- *Leave-One-Out CV (LOOCV) is also a special case that means $k=n$, each observation is used as a single test case.*\n",
        "\n",
        "$CV_{MSE}$ gives an estimate of the expected prediction error on new/unseen data.  \n",
        "\n",
        "Lower $CV_{MSE}$ means better generalization performance.  \n",
        "\n",
        "This method helps also detect overfitting that means a model with very low training MSE but high $CV_{MSE}$ is overfitting the training data.\n",
        "\n",
        "**via Residuals**\n",
        "\n",
        "$$\n",
        "e_i = y_i - \\hat{y}_i\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $y_i$: observed value for observation $i$  \n",
        "- $\\hat{y}_i$: predicted value from the regression model\n",
        "\n",
        "**Interpretation:**  \n",
        "- The residual represents the difference between the actual and predicted value for each observation and small residuals indicate that the model predictions are close to the actual values.\n",
        "\n",
        "**via Mean Squared Error (MSE)**\n",
        "\n",
        "$$\n",
        "MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\frac{RSS}{n}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $n$: number of observations  \n",
        "- $RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$\n",
        "\n",
        "**Interpretation:**  \n",
        "- MSE measures the average squared difference between observed and predicted values and lower MSE indicates better model fit, but the unit is the square of the dependent variable.\n",
        "\n",
        "**via Root Mean Squared Error (RMSE)**\n",
        "\n",
        "$$\n",
        "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "- RMSE converts MSE back to the original units of the dependent variable and it represents the typical size of the prediction error.\n",
        "\n",
        "**via Mean Absolute Error (MAE)**\n",
        "\n",
        "$$\n",
        "MAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "- MAE is the average of absolute residuals while more robust to outliers than MSE/RMSE and gives a straightforward measure of average prediction error.\n",
        "\n",
        "**via R-squared ($R^2$)**\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} = 1 - \\frac{RSS}{TSS}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $TSS = \\sum_{i=1}^n (y_i - \\bar{y})^2$: total variance of the observed data  \n",
        "- $\\bar{y}$: mean of observed values\n",
        "\n",
        "**Interpretation:**  \n",
        "- $R^2$ measures the proportion of variance in the dependent variable explained by the model and values closer to 1 indicate better fit; 0 means the model explains nothing.\n",
        "\n",
        "#### Prediction\n",
        "\n",
        "Linear regression model for prediction is:\n",
        "\n",
        "$$\n",
        "\\hat{y}_{new} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{new}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\hat{\\beta}_0$: estimated intercept  \n",
        "- $\\hat{\\beta}_1$: estimated slope coefficient  \n",
        "- $x_{new}$: new value of the predictor variable  \n",
        "- $\\hat{y}_{new}$: predicted value of the response variable\n",
        "\n",
        "For predicting a new individual observation at $x_0$ via **prediction interval (PI)** that estimates the range in which a new individual response lies for a given $x_0$:\n",
        "\n",
        "$$\n",
        "\\hat{y}_0 \\; \\pm \\; t_{\\alpha/2, \\, n-2} \\cdot SE_{pred}(\\hat{y}_0)\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\hat{y}_0$: predicted mean response at $x_0$  \n",
        "- $SE_{pred}(\\hat{y}_0) = \\sqrt{SE(\\hat{y}_0)^2 + \\sigma^2}$  \n",
        "- $\\sigma^2$: variance of the error term (residual variance)\n",
        "\n",
        "Also, to construct a confidence interval for the mean predicted value at a given $x_{0}$ via **confidence interval (CI)** that estimates the range in which the mean response lies for a given $x_0$:\n",
        "\n",
        "$$\n",
        "\\hat{y}_0 \\; \\pm \\; t_{\\alpha/2, \\, n-2} \\cdot SE(\\hat{y}_0)\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\hat{y}_0 = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_0$: predicted mean response at $x_0$  \n",
        "- $t_{\\alpha/2, \\, n-2}$: critical value from the $t$-distribution with $n-2$ degrees of freedom  \n",
        "- $SE(\\hat{y}_0)$: standard error of the predicted mean  \n",
        "\n",
        "The PI is always wider than the CI, because it includes both the uncertainty of the mean estimate and the random error of a new observation.\n",
        "\n",
        "**Extrapolation** occurs when using a regression model to predict values outside the range of the observed data and it can lead to unreliable predictions, as the model was not trained for values outside the observed range. Even if the model is linear, the true relationship outside the data range may differ.\n",
        "\n",
        "#### Diagnostics\n",
        "\n",
        "**Outliers**\n",
        "\n",
        "Observations with unusually large residuals compared to what the model predicts.  \n",
        "- **Check:**  \n",
        "  - Standardized residuals ($|e_i| > 2$ or $3$).  \n",
        "  - Studentized residuals.\n",
        "\n",
        "**Influential Points**\n",
        "\n",
        "Points that disproportionately affect the estimated regression coefficients.  \n",
        "- **Check:**  \n",
        "  - Cook’s Distance ($D_i > 1$ is often problematic).  \n",
        "  - Leverage values ($h_{ii}$, diagonal elements of the hat matrix).\n",
        "\n",
        "**Heteroskedasticity**\n",
        "\n",
        "The variance of the residuals is not constant ($Var(\\varepsilon_i) \\neq \\sigma^2$).  \n",
        "- **Check:**  \n",
        "  - Residuals vs. Fitted plot (fan or cone shape suggests heteroskedasticity).  \n",
        "  - Breusch–Pagan test.\n",
        "\n",
        "**Non-normality of Errors**\n",
        "\n",
        "Residuals are not normally distributed ($\\varepsilon_i \\sim N(0, \\sigma^2)$ assumption violated).  \n",
        "- **Check:**  \n",
        "  - Q-Q plot.  \n",
        "  - Shapiro-Wilk test.\n",
        "\n",
        "**Correlated Errors**\n",
        "\n",
        "Residuals are dependent on each other (common in time-series data).  \n",
        "- **Check:**  \n",
        "  - Durbin–Watson statistic ($DW \\approx 2$ is good; $<1$ or $>3$ indicates problems).  \n",
        "  - Residuals vs. Time plot.\n",
        "\n",
        "**Non-Linearity**\n",
        "\n",
        "If the true relationship is not linear, the model is misspecified.  \n",
        "- **Check:**  \n",
        "  - Partial residual plots (component + residual plots).  \n",
        "  - Ramsey RESET test.\n",
        "\n",
        "Importantly for simple linear regression, no fitting or regularizing are needed."
      ],
      "metadata": {
        "id": "cVWn-INTTPes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple Linear Regression Model"
      ],
      "metadata": {
        "id": "KPrqkyAsTPzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model\n",
        "\n",
        "Multiple linear regression model is:\n",
        "\n",
        "$$\n",
        "y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $y_i$ : dependent variable (outcome) for observation $i$\n",
        "- $x_{ij}$ : value of the $j$-th independent variable (predictor) for observation $i$  \n",
        "- $\\beta_0$ : intercept (expected value of $y$ when all predictors are 0)  \n",
        "- $\\beta_j$ : regression coefficient for predictor $x_{ij}$ (change in $y$ for a one-unit increase in $x_{ij}$, holding other predictors constant)  \n",
        "- $\\varepsilon_i$ : error term for observation $i$, assumed to have mean 0  \n",
        "\n",
        "**While:**\n",
        "\n",
        "- **Known (from the data):** $x_{ij}, y_i$ (the observations, given in the dataset).  \n",
        "- **Unknown but to be estimated:** $\\beta_0, \\beta_1, \\dots, \\beta_p$ (parameters of the regression model).  \n",
        "- **Not directly known but assumed:** $\\varepsilon_i$ (error terms, assumed to have mean 0, constant variance, and no correlation across observations).  \n",
        "\n",
        "In regression, the **Residual Sum of Squares (RSS)** measures the total squared difference between the observed values $y_i$ and the predicted values $\\hat{y}_i$:\n",
        "\n",
        "$$\n",
        "RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "- $y_i$ is the observed value for observation $i$.  \n",
        "- $\\hat{y}_i$ is the predicted value from the regression model:  \n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2} + \\cdots + \\hat{\\beta}_p x_{ip}\n",
        "$$  \n",
        "\n",
        "- The difference $e_i = y_i - \\hat{y}_i$ is called the residual.  \n",
        "\n",
        "To calculate $\\beta_0, \\beta_1, \\dots, \\beta_p$ to construct the model via **Ordinary Least Squares (OLS)** by minimizing the RSS:\n",
        "\n",
        "$$\n",
        "RSS(\\beta_0, \\beta_1, \\dots, \\beta_p) = \\sum_{i=1}^n \\Big( y_i - (\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}) \\Big)^2\n",
        "$$\n",
        "\n",
        "- The residual for observation $i$ is $e_i = y_i - \\hat{y}_i$.  \n",
        "- Minimizing $RSS$ gives the “best-fitting hyperplane” through the data points.  \n",
        "\n",
        "#### Weighting\n",
        "\n",
        "Weighting is used when some observations are more important or more reliable than others.\n",
        "\n",
        "Weighted multiple linear regression model is:\n",
        "\n",
        "$$\n",
        "y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\varepsilon_i, \\quad i = 1,2,\\dots,n\n",
        "$$\n",
        "\n",
        "- Standard regression minimizes the Residual Sum of Squares (RSS):\n",
        "\n",
        "$$\n",
        "RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "- Weighted regression introduces weights $w_i > 0$ for each observation:\n",
        "\n",
        "$$\n",
        "WRSS = \\sum_{i=1}^n w_i \\left(y_i - \\hat{y}_i\\right)^2\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $w_i$: weight for observation $i$  \n",
        "- $\\hat{y}_i = \\hat{\\beta}_0 + \\sum_{j=1}^p \\hat{\\beta}_j x_{ij}$  \n",
        "\n",
        "Minimize $WRSS$ with respect to all coefficients $\\beta_0, \\beta_1, \\dots, \\beta_p$:\n",
        "\n",
        "$$\n",
        "(\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p) = \\arg\\min_{\\beta_0, \\beta_1, \\dots, \\beta_p} \\sum_{i=1}^n w_i \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij}\\right)^2\n",
        "$$\n",
        "\n",
        "- In matrix form:\n",
        "\n",
        "$$\n",
        "\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\top \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{W} \\mathbf{y}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $\\mathbf{X}$ is the $n \\times (p+1)$ design matrix (including a column of 1's for the intercept)  \n",
        "- $\\mathbf{W} = \\text{diag}(w_1, w_2, \\dots, w_n)$ is the diagonal **weight matrix**  \n",
        "- $\\mathbf{y}$ is the vector of observed responses  \n",
        "- $\\hat{\\boldsymbol{\\beta}} = (\\hat{\\beta}_0, \\hat{\\beta}_1, \\dots, \\hat{\\beta}_p)^\\top$  \n",
        "\n",
        "Observations with larger weights $w_i$ have more influence on the fitted hyperplane to reduce the impact of less reliable points on the coefficient estimates.  \n",
        "\n",
        "#### Interpretation\n",
        "\n",
        "**via Correlated Predictors**\n",
        "\n",
        "The coefficient $\\beta_j$ represents the expected change in $y$ for a one-unit increase in $x_j$, holding all other predictors constant:\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2} + \\cdots + \\hat{\\beta}_p x_{ip}\n",
        "$$\n",
        "\n",
        "- If predictors are correlated, the interpretation of $\\beta_j$ depends on the values of other predictors.  \n",
        "- High correlation can make $\\hat{\\beta}_j$ unstable (large standard errors).\n",
        "\n",
        "**via Multicollinearity**\n",
        "\n",
        "Occurs when predictors are highly linearly related and it inflates standard errors.\n",
        "\n",
        "- Mathematically, this makes $(\\mathbf{X}^\\top \\mathbf{X})$ nearly singular, increasing variance of coefficient estimates:\n",
        "\n",
        "$$\n",
        "Var(\\hat{\\beta}) = \\sigma^2 (\\mathbf{X}^\\top \\mathbf{X})^{-1}\n",
        "$$\n",
        "\n",
        "- Detect using Variance Inflation Factor (VIF):\n",
        "\n",
        "$$\n",
        "VIF_j = \\frac{1}{1 - R_j^2}\n",
        "$$\n",
        "\n",
        "where $R_j^2$ is the $R^2$ of regressing $x_j$ on all other predictors.  \n",
        "\n",
        "**via Confounding Variables**\n",
        "\n",
        "It can bias estimates if omitted and a confounder $x_k$ affects both $y$ and another predictor $x_j$.  \n",
        "\n",
        "- Ignoring $x_k$ can bias $\\hat{\\beta}_j$:  \n",
        "\n",
        "$$\n",
        "Bias(\\hat{\\beta}_j) = Cov(x_j, x_k) \\cdot \\beta_k / Var(x_j)\n",
        "$$\n",
        "\n",
        "- Including $x_k$ in the model controls for its confounding effect.\n",
        "\n",
        "**via Interaction Terms**\n",
        "\n",
        "It show how the effect of one predictor depends on another and if the effect of $x_1$ on $y$ depends on $x_2$, include an interaction:\n",
        "\n",
        "$$\n",
        "y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 (x_{i1} \\cdot x_{i2}) + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "  - $\\beta_3$: additional change in $y$ for a one-unit increase in $x_1$ when $x_2$ increases by one unit.\n",
        "\n",
        "**via Main Effects**\n",
        "\n",
        "It represent the isolated effect of each predictor and the main effect of a predictor $x_j$ is its effect ignoring interactions:\n",
        "\n",
        "$$\n",
        "\\text{Main effect of } x_j = \\frac{\\partial \\hat{y}_i}{\\partial x_j} \\text{ when all interaction terms are 0 or baseline.}\n",
        "$$\n",
        "\n",
        "- If interaction terms exist, main effects are conditional and should be interpreted at a reference value of the interacting variable(s).  \n",
        "\n",
        "#### Performance\n",
        "\n",
        "**Cross-Validation**\n",
        "\n",
        "To estimate the generalization performance of a multiple linear regression model on unseen data.\n",
        "\n",
        "**k-Fold Cross-Validation**\n",
        "\n",
        "1. Split the data into $k$ roughly equal folds (subsets): $D_1, D_2, \\dots, D_k$.  \n",
        "2. For each fold $j = 1, \\dots, k$:\n",
        "   - Train the model on the remaining $k-1$ folds: $D_{-j} = D \\setminus D_j$  \n",
        "   - Fit the model to obtain $\\hat{\\boldsymbol{\\beta}}^{(-j)} = (\\hat{\\beta}_0^{(-j)}, \\hat{\\beta}_1^{(-j)}, \\dots, \\hat{\\beta}_p^{(-j)})$  \n",
        "   - Predict on the left-out fold $D_j$:\n",
        "\n",
        "$$\n",
        "\\hat{y}_i^{(-j)} = \\hat{\\beta}_0^{(-j)} + \\hat{\\beta}_1^{(-j)} x_{i1} + \\hat{\\beta}_2^{(-j)} x_{i2} + \\cdots + \\hat{\\beta}_p^{(-j)} x_{ip}, \\quad i \\in D_j\n",
        "$$\n",
        "\n",
        "3. Compute the prediction error (e.g., Mean Squared Error) for each fold:\n",
        "\n",
        "$$\n",
        "MSE_j = \\frac{1}{|D_j|} \\sum_{i \\in D_j} \\left(y_i - \\hat{y}_i^{(-j)}\\right)^2\n",
        "$$\n",
        "\n",
        "4. Average over all folds to get cross-validated MSE:\n",
        "\n",
        "$$\n",
        "CV_{MSE} = \\frac{1}{k} \\sum_{j=1}^{k} MSE_j\n",
        "$$\n",
        "\n",
        "- *Common choices are $k=5$ or $k=10$*  \n",
        "- *Leave-One-Out CV (LOOCV) is also a special case: $k=n$, each observation is used as a single test case.*  \n",
        "\n",
        "$CV_{MSE}$ gives an estimate of the expected prediction error on new/unseen data.  \n",
        "\n",
        "Lower $CV_{MSE}$ means better generalization performance.  \n",
        "\n",
        "Helps detect overfitting means that a model with very low training MSE but high $CV_{MSE}$ is likely overfitting.\n",
        "\n",
        "**via Residuals**\n",
        "\n",
        "$$\n",
        "e_i = y_i - \\hat{y}_i\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $y_i$: observed value for observation $i$  \n",
        "- $\\hat{y}_i$: predicted value from the multiple regression model  \n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i1} + \\hat{\\beta}_2 x_{i2} + \\cdots + \\hat{\\beta}_p x_{ip}\n",
        "$$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- The residual represents the difference between the actual and predicted value for each observation.  \n",
        "- Small residuals indicate that the model predictions are close to the actual values.  \n",
        "\n",
        "**via Mean Squared Error (MSE)**\n",
        "\n",
        "$$\n",
        "MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\frac{RSS}{n}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $n$: number of observations  \n",
        "- $RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$\n",
        "\n",
        "**Interpretation:**  \n",
        "- MSE measures the average squared difference between observed and predicted values.  \n",
        "- Lower MSE indicates better model fit, but the unit is the square of the dependent variable.  \n",
        "\n",
        "**via Root Mean Squared Error (RMSE)**\n",
        "\n",
        "$$\n",
        "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "- RMSE converts MSE back to the original units of the dependent variable and it represents the typical size of the prediction error.  \n",
        "\n",
        "**via Mean Absolute Error (MAE)**\n",
        "\n",
        "$$\n",
        "MAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "- MAE is the average of absolute residuals and more robust to outliers than MSE/RMSE and gives a straightforward measure of average prediction error.  \n",
        "\n",
        "**via R-squared ($R^2$)**\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} = 1 - \\frac{RSS}{TSS}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $TSS = \\sum_{i=1}^n (y_i - \\bar{y})^2$: total variance of the observed data  \n",
        "- $\\bar{y}$: mean of observed values  \n",
        "\n",
        "**Interpretation:**  \n",
        "- $R^2$ measures the proportion of variance in the dependent variable explained by the model.  \n",
        "- Values closer to 1 indicate better fit; 0 means the model explains nothing.  \n",
        "\n",
        "**via Adjusted R-squared ($\\bar{R}^2$)**\n",
        "\n",
        "$$\n",
        "\\bar{R}^2 = 1 - \\left(1 - R^2\\right)\\frac{n-1}{n-p-1}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $n$: number of observations  \n",
        "- $p$: number of predictors (independent variables, excluding intercept)  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Adjusted $R^2$ penalizes adding irrelevant predictors to the model and it only increases if the new predictor improves the model more than would be expected by chance and preferred over $R^2$ in multiple regression when comparing models with different numbers of predictors.  \n",
        "- Values closer to 1 indicate better fit; 0 means the model explains nothing.\n",
        "\n",
        "#### Selection\n",
        "\n",
        "**via Stepwise Regression**\n",
        "\n",
        "Stepwise regression is a model selection technique used when there are multiple predictors ($x_1, x_2, \\dots, x_p$) and we want to find the best subset of predictors for the model.\n",
        "\n",
        "Stepwise regression iteratively adds or removes predictors based on a selection criterion (e.g., Adjusted $R^2$ & AIC).\n",
        "\n",
        "**Forward Selection:**\n",
        "1. Start with no predictors: $y_i = \\beta_0 + \\varepsilon_i$  \n",
        "2. For each candidate predictor $x_j$, fit the model:\n",
        "\n",
        "$$\n",
        "y_i = \\beta_0 + \\beta_j x_{ij} + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "3. Choose the predictor with the best improvement according to the selection criterion.  \n",
        "4. Repeat by adding one predictor at a time until no further improvement is possible.\n",
        "\n",
        "**Backward Elimination:**\n",
        "1. Start with all predictors:  \n",
        "\n",
        "$$\n",
        "y_i = \\beta_0 + \\sum_{j=1}^{p} \\beta_j x_{ij} + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "2. Remove the least significant predictor according to the criterion.  \n",
        "3. Repeat until all remaining predictors meet the significance threshold.\n",
        "\n",
        "**Stepwise (Both Directions):**\n",
        "- Combines forward selection and backward elimination: predictors can be added or removed at each step.\n",
        "\n",
        "**Selection Criteria**\n",
        "\n",
        "- **Adjusted $R^2$**:\n",
        "\n",
        "$$\n",
        "\\text{Adjusted } R^2 = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}\n",
        "$$\n",
        "\n",
        "- **Akaike Information Criterion (AIC)**:\n",
        "\n",
        "$$\n",
        "AIC = n \\ln\\left(\\frac{RSS}{n}\\right) + 2(p+1)\n",
        "$$\n",
        "\n",
        "Here, $RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ and $p$ is the number of predictors in the model.  \n",
        "\n",
        "#### Prediction\n",
        "\n",
        "Multiple linear regression model for prediction is:\n",
        "\n",
        "$$\n",
        "\\hat{y}_{new} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{new,1} + \\hat{\\beta}_2 x_{new,2} + \\cdots + \\hat{\\beta}_p x_{new,p}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\hat{\\beta}_0$: estimated intercept  \n",
        "- $\\hat{\\beta}_j$: estimated slope coefficient for predictor $j$  \n",
        "- $x_{new,j}$: new value of the $j$-th predictor variable  \n",
        "- $\\hat{y}_{new}$: predicted value of the response variable  \n",
        "\n",
        "For predicting a new individual observation at predictor vector $\\mathbf{x}_0 = (1, x_{0,1}, x_{0,2}, \\dots, x_{0,p})^\\top$ via **prediction interval (PI)** that estimates the range in which a new individual response lies for given predictors:\n",
        "\n",
        "$$\n",
        "\\hat{y}_0 \\; \\pm \\; t_{\\alpha/2, \\, n-p-1} \\cdot SE_{pred}(\\hat{y}_0)\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\hat{y}_0 = \\mathbf{x}_0^\\top \\hat{\\beta}$: predicted mean response at $\\mathbf{x}_0$  \n",
        "- $SE_{pred}(\\hat{y}_0) = \\sqrt{SE(\\hat{y}_0)^2 + \\sigma^2}$  \n",
        "- $\\sigma^2$: variance of the error term (residual variance)  \n",
        "\n",
        "To construct a confidence interval for the mean predicted value at given predictors $\\mathbf{x}_0$ via **confidence interval (CI)** that estimates the range in which the mean response lies:\n",
        "\n",
        "$$\n",
        "\\hat{y}_0 \\; \\pm \\; t_{\\alpha/2, \\, n-p-1} \\cdot SE(\\hat{y}_0)\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\hat{y}_0 = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{0,1} + \\cdots + \\hat{\\beta}_p x_{0,p}$: predicted mean response at $\\mathbf{x}_0$  \n",
        "- $t_{\\alpha/2, \\, n-p-1}$: critical value from the $t$-distribution with $n-p-1$ degrees of freedom  \n",
        "- $SE(\\hat{y}_0)$: standard error of the predicted mean  \n",
        "\n",
        "The prediction interval (PI) is always wider than the confidence interval (CI), because PI accounts for both the uncertainty in the mean estimate and the random error of a new observation.  \n",
        "\n",
        "**Extrapolation** occurs when using a regression model to predict values outside the range of the observed data. This can lead to unreliable predictions, because the model was not trained on such values. Even if the model is linear, the true relationship outside the observed range may differ.\n",
        "\n",
        "#### Diagnostics\n",
        "\n",
        "**Outliers**\n",
        "\n",
        "Observations with unusually large residuals compared to what the model predicts.  \n",
        "- **Check:**  \n",
        "  - Standardized residuals ($|e_i| > 2$ or $3$).  \n",
        "  - Studentized residuals.  \n",
        "  - In multiple regression, consider **Mahalanobis distance** to detect outliers in multivariate predictor space.\n",
        "\n",
        "**Influential Points**\n",
        "\n",
        "Points that disproportionately affect the estimated regression coefficients.  \n",
        "- **Check:**  \n",
        "  - Cook’s Distance ($D_i > 1$ is often problematic).  \n",
        "  - Leverage values ($h_{ii}$, diagonal elements of the hat matrix $\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^\\top \\mathbf{X})^{-1}\\mathbf{X}^\\top$).  \n",
        "  - In multiple regression, influential points can be unusual **combinations of predictor values**, not just extreme in a single predictor.\n",
        "\n",
        "**Heteroskedasticity**\n",
        "\n",
        "The variance of the residuals is not constant ($Var(\\varepsilon_i) \\neq \\sigma^2$).  \n",
        "- **Check:**  \n",
        "  - Residuals vs. Fitted plot (fan or cone shape suggests heteroskedasticity).  \n",
        "  - Breusch–Pagan test.  \n",
        "  - White test (robust to model specification in multiple regression).\n",
        "\n",
        "**Non-normality of Errors**\n",
        "\n",
        "Residuals are not normally distributed ($\\varepsilon_i \\sim N(0, \\sigma^2)$ assumption violated).  \n",
        "- **Check:**  \n",
        "  - Q-Q plot.  \n",
        "  - Shapiro-Wilk test.  \n",
        "  - Multiple regression often tolerates mild non-normality if $n$ is large (Central Limit Theorem).\n",
        "\n",
        "**Correlated Errors**\n",
        "\n",
        "Residuals are dependent on each other (common in time-series or panel data).  \n",
        "- **Check:**  \n",
        "  - Durbin–Watson statistic ($DW \\approx 2$ is good; $<1$ or $>3$ indicates problems).  \n",
        "  - Residuals vs. Time plot.  \n",
        "\n",
        "**Non-Linearity**\n",
        "\n",
        "If the true relationship is not linear in the predictors, the model is misspecified.  \n",
        "- **Check:**  \n",
        "  - Partial residual plots (component + residual plots) for each predictor.  \n",
        "  - Ramsey RESET test.  \n",
        "  - Consider adding polynomial or interaction terms in multiple regression.\n",
        "\n",
        "#### Fitting\n",
        "\n",
        "**Overall F-test**\n",
        "\n",
        "Tests whether the regression model provides a better fit than a model with no predictors (intercept only).\n",
        "\n",
        "$$\n",
        "H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0 \\quad \\text{vs.} \\quad H_a: \\text{at least one } \\beta_j \\neq 0\n",
        "$$\n",
        "\n",
        "F-statistic:\n",
        "\n",
        "$$\n",
        "F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)} = \\frac{ESS / p}{RSS / (n-p-1)}\n",
        "$$\n",
        "\n",
        "Where:  \n",
        "- $TSS = \\sum_{i=1}^{n} (y_i - \\bar{y})^2$ is the total sum of squares  \n",
        "- $RSS = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ is the residual sum of squares  \n",
        "- $ESS = TSS - RSS$ is the explained sum of squares  \n",
        "- $p$ is the number of predictors  \n",
        "- $n$ is the number of observations  \n",
        "\n",
        "**Interpretation:**  \n",
        "\n",
        "- Large $F$ (small $p$-value) indicates that the model explains a significant amount of variance in $y$ compared to the null model.\n",
        "\n",
        "**Coefficient t-tests**\n",
        "\n",
        "Test whether each individual predictor has a statistically significant effect on the dependent variable.\n",
        "\n",
        "$$\n",
        "t_j = \\frac{\\hat{\\beta}_j}{SE(\\hat{\\beta}_j)}\n",
        "$$\n",
        "\n",
        "Where $SE(\\hat{\\beta}_j)$ is the standard error of the coefficient $\\hat{\\beta}_j$.  \n",
        "\n",
        "- Null hypothesis: $H_0: \\beta_j = 0$  \n",
        "- Alternative hypothesis: $H_a: \\beta_j \\neq 0$  \n",
        "\n",
        "**Interpretation:**  \n",
        "\n",
        "- Large $|t_j|$ (small $p$-value) suggests that predictor $x_j$ significantly contributes to the model.\n",
        "\n",
        "#### Regularizing\n",
        "\n",
        "Regularizing is used to prevent overfitting and improve prediction performance when predictors are highly correlated or numerous.\n",
        "\n",
        "**L2 Regularization (Ridge)**\n",
        "\n",
        "Adds a penalty proportional to the square of the coefficients.\n",
        "\n",
        "$$\n",
        "\\hat{\\boldsymbol{\\beta}}^{ridge} = \\arg\\min_{\\boldsymbol{\\beta}} \\Bigg\\{ \\sum_{i=1}^n \\left( y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\Bigg\\}\n",
        "$$\n",
        "\n",
        "Where:  \n",
        "- $\\lambda \\ge 0$: regularization strength (hyperparameter) & chosen via cross-validation to optimize predictive performance.\n",
        "\n",
        "**Interpretation:**  \n",
        "\n",
        "- Shrinks coefficients towards zero.\n",
        "\n",
        "**L1 Regularization (Lasso)**\n",
        "\n",
        "Adds a penalty proportional to the absolute value of the coefficients\n",
        "\n",
        "$$\n",
        "\\hat{\\boldsymbol{\\beta}}^{lasso} = \\arg\\min_{\\boldsymbol{\\beta}} \\Bigg\\{ \\sum_{i=1}^n \\left( y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)^2 + \\lambda \\sum_{j=1}^p |\\beta_j| \\Bigg\\}\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "\n",
        "- It can shrink some coefficients exactly to zero means automatic feature selection.\n",
        "\n",
        "Both L1 and L2 can be combined in **Elastic Net** regularization."
      ],
      "metadata": {
        "id": "vCwdpexNTR3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELS FOR CLASSIFICATION"
      ],
      "metadata": {
        "id": "W6c5mzjITHA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Logistic Regression Model"
      ],
      "metadata": {
        "id": "dRNgot1nTVB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model\n",
        "\n",
        "Binary logistic regression model is:\n",
        "\n",
        "$$\n",
        "p_i = P(y_i = 1 \\mid x_i) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_i)}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $y_i \\in \\{0,1\\}$: binary dependent variable (outcome) for observation $i$  \n",
        "- $x_i$: independent variable (predictor) for observation $i$  \n",
        "- $\\beta_0$: intercept (baseline log-odds of $y=1$ when $x=0$)  \n",
        "- $\\beta_1$: slope (change in the log-odds of $y=1$ for a one-unit increase in $x$)  \n",
        "- $p_i$: predicted probability that $y_i=1$ given $x_i$  \n",
        "\n",
        "Instead of modeling $y_i$ directly, logistic regression models the log-odds (logit):\n",
        "\n",
        "$$\n",
        "\\text{logit}(p_i) = \\ln\\left(\\frac{p_i}{1-p_i}\\right) = \\beta_0 + \\beta_1 x_i\n",
        "$$\n",
        "\n",
        "**While:**\n",
        "\n",
        "- **Known (from the data):** $x_i, y_i$ (observations, with $y_i \\in \\{0,1\\}$).  \n",
        "- **Unknown but to be estimated:** $\\beta_0, \\beta_1$ (parameters of the logistic model).  \n",
        "- **Not directly known but assumed:** The probabilities $p_i$, derived from the logistic function.  \n",
        "\n",
        "In logistic regression, parameters are estimated by **Maximum Likelihood Estimation (MLE)**.\n",
        "\n",
        "The MLE is:\n",
        "\n",
        "$$\n",
        "L(\\beta_0, \\beta_1) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i}\n",
        "$$\n",
        "\n",
        "And the log-MLE is:\n",
        "\n",
        "$$\n",
        "\\ell(\\beta_0, \\beta_1) = \\sum_{i=1}^n \\Big[ y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i) \\Big]\n",
        "$$\n",
        "\n",
        "- Estimators $\\hat{\\beta}_0, \\hat{\\beta}_1$ are obtained by maximizing $\\ell(\\beta_0, \\beta_1)$.  \n",
        "- This gives the “best-fitting logistic curve” that separates the two outcome classes.\n",
        "\n",
        "#### Performance\n",
        "\n",
        "**Cross-Validation**\n",
        "\n",
        "To estimate the generalization performance of the logistic regression model on unseen data.  \n",
        "\n",
        "**k-Fold Cross-Validation**\n",
        "\n",
        "1. Split the data into $k$ roughly equal folds (subsets): $D_1, D_2, \\dots, D_k$.  \n",
        "2. For each fold $j = 1, \\dots, k$:\n",
        "   - Train the model on the remaining $k-1$ folds: $D_{-j} = D \\setminus D_j$  \n",
        "   - Fit the model to obtain $\\hat{\\beta}_0^{(-j)}, \\hat{\\beta}_1^{(-j)}$  \n",
        "   - Predict on the left-out fold $D_j$: $\\hat{p}_i^{(-j)} = \\frac{1}{1 + e^{-(\\hat{\\beta}_0^{(-j)} + \\hat{\\beta}_1^{(-j)} x_i)}}$ for $i \\in D_j$  \n",
        "3. Compute the prediction error using a classification loss (e.g., Log Loss, Accuracy, AUC) for each fold.  \n",
        "\n",
        "- *Common choices are $k=5$ or $k=10$*  \n",
        "- *Leave-One-Out CV (LOOCV) is also a special case that means $k=n$, each observation is used as a single test case.*  \n",
        "\n",
        "Cross-validation gives an estimate of the expected performance on new/unseen data.  \n",
        "\n",
        "Lower log loss or higher accuracy indicates better generalization performance.  \n",
        "\n",
        "This method also helps detect overfitting that a model with very high training accuracy but much lower cross-validation accuracy is overfitting the training data.\n",
        "\n",
        "**via Accuracy**\n",
        "\n",
        "Proportion of all predictions that are correct.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}(\\hat{y}_i = y_i)\n",
        "$$  \n",
        "\n",
        "Where $\\hat{y}_i = 1$ if $\\hat{p}_i \\geq 0.5$, else $0$.   \n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- Higher percentage means the model correctly classifies more observations.\n",
        "\n",
        "**via Precision**\n",
        "\n",
        "Proportion of predicted positives that are actually positive.  \n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $TP$: True Positives (correctly predicted positives)  \n",
        "- $FP$: False Positives (incorrectly predicted positives)  \n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- Higher percentage means the model makes fewer false positive errors.\n",
        "\n",
        "**via Recall (Sensitivity)**\n",
        "\n",
        "Proportion of actual positives that are correctly identified.\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $FN$: False Negatives (missed positives)  \n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- Higher percentage means the model detects more of the positive cases.\n",
        "\n",
        "**via Specificity**\n",
        "\n",
        "Proportion of actual negatives that are correctly identified.   \n",
        "\n",
        "$$\n",
        "\\text{Specificity} = \\frac{TN}{TN + FP}\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $TN$: True Negatives (correctly predicted negatives)  \n",
        "- $FP$: False Positives (incorrectly predicted positives)  \n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- Higher percentage means the model correctly rejects more negative cases, avoiding false alarms.    \n",
        "\n",
        "**via F1-score**\n",
        "\n",
        "Harmonic mean of Precision and Recall.   \n",
        "\n",
        "$$\n",
        "F1 = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$  \n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- Balances false positives and false negatives to get higher percentage indicates better balanced performance.  \n",
        "\n",
        "**via ROC To AUC**\n",
        "\n",
        "- ROC (Receiver Operating Characteristic) curve plots True Positive Rate (TPR) as TPR = Recall vs. False Positive Rate (FPR) as FPR = 1-Specificity to get AUC (Area Under Curve) summarizes the model’s ability to discriminate between classes.  \n",
        "\n",
        "**Interpretation:**  \n",
        "\n",
        "- AUC = 0.5 means random guessing and AUC closer to 1 means better discrimination.  \n",
        "\n",
        "**via Log Loss (Cross-Entropy Loss)**  \n",
        "\n",
        "Penalizes confident but wrong predictions.\n",
        "\n",
        "$$\n",
        "\\text{LogLoss} = -\\frac{1}{n} \\sum_{i=1}^n \\Big[ y_i \\ln(\\hat{p}_i) + (1-y_i) \\ln(1-\\hat{p}_i) \\Big]\n",
        "$$  \n",
        "\n",
        "**Interpretation:**   \n",
        "\n",
        "- Higher log loss means heavily penalizes confident incorrect predictions.  \n",
        "\n",
        "#### Prediction\n",
        "\n",
        "Binary logistic regression model for prediction is:\n",
        "\n",
        "$$\n",
        "\\hat{p}_{new} = \\frac{1}{1 + e^{-(\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{new})}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\hat{\\beta}_0$: estimated intercept  \n",
        "- $\\hat{\\beta}_1$: estimated slope coefficient  \n",
        "- $x_{new}$: new value of the predictor variable  \n",
        "- $\\hat{p}_{new}$: predicted probability that $y=1$ for the new observation\n",
        "\n",
        "To estimate the uncertainty of the predicted probability $\\hat{p}_0$ at $x_0$, a **confidence interval** can be constructed using the standard error of the logit:\n",
        "\n",
        "1. Compute the logit of the predicted probability:\n",
        "\n",
        "$$\n",
        "\\hat{\\text{logit}}_0 = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_0\n",
        "$$\n",
        "\n",
        "2. Construct a CI for the logit:\n",
        "\n",
        "$$\n",
        "\\hat{\\text{logit}}_0 \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\text{logit}}_0)\n",
        "$$\n",
        "\n",
        "while\n",
        "\n",
        "$$\n",
        "SE(\\hat{\\text{logit}}_0) = \\sqrt{x_0^\\top \\, \\text{Cov}(\\hat{\\beta}) \\, x_0}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $SE(\\hat{\\text{logit}}_0)$: standard error of the predicted logit  \n",
        "- $x_0 = \\begin{bmatrix} 1 \\\\ x_0 \\end{bmatrix}$: predictor vector including intercept  \n",
        "- $\\text{Cov}(\\hat{\\beta})$: estimated covariance matrix of the coefficients  \n",
        "- $z_{\\alpha/2}$: critical value from the standard normal distribution (e.g., 1.96 for 95\\% CI)  \n",
        "\n",
        "3. Transform back to probability scale using the logistic function:\n",
        "\n",
        "$$\n",
        "\\hat{p}_0 = \\frac{1}{1 + e^{-\\hat{\\text{logit}}_0}}\n",
        "$$\n",
        "\n",
        "CI gives a range in which the true probability for a given $x_0$ is likely to lie.  \n",
        "\n",
        "Unlike linear regression, there is no standard **prediction interval** for a single observation, because the response is binary.  \n",
        "\n",
        "**Extrapolation** occurs when $x_{new}$ is outside the range of observed $x_i$; predicted probabilities may be unreliable.\n",
        "\n",
        "#### Lifting\n",
        "\n",
        "Measures the effectiveness of a predictive model compared to random guessing especially in rare classess like fraud detection.    \n",
        "\n",
        "$$\n",
        "\\text{Lift} = \\frac{\\text{Proportion of positives in model-selected group}}{\\text{Proportion of positives in entire population}}\n",
        "$$\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- Lift > 1 means model is better than random at identifying positives.  \n",
        "- Lift = 1 means model is no better than random.  \n",
        "\n",
        "When the positive class is rare, standard models may underperform and the techniques like oversampling, undersampling & weighting can help increase the model's ability to identify the rare class, improving the lift metrics.\n",
        "\n",
        "1. **Oversampling (Synthetic or Duplicate Sampling)**\n",
        "\n",
        "Increase the number of minority class samples:\n",
        "\n",
        "$$\n",
        "n_{minority}^{new} > n_{minority}^{original}\n",
        "$$\n",
        "\n",
        "By synthetic generation (SMOTE) for each minority sample $x_i$, generate a new sample along the line connecting $x_i$ to one of its $k$ nearest neighbors $x_{nn}$:\n",
        "\n",
        "$$\n",
        "x_{new} = x_i + \\lambda \\cdot (x_{nn} - x_i), \\quad \\lambda \\sim U(0,1)\n",
        "$$\n",
        "\n",
        "Model sees more minority examples that learns rare class patterns means the lift increases.\n",
        "\n",
        "2. **Undersampling (Majority Reduction)**\n",
        "\n",
        "Reduce the number of majority class samples:\n",
        "\n",
        "$$\n",
        "n_{majority}^{new} < n_{majority}^{original}\n",
        "$$\n",
        "\n",
        "Randomly select a subset of majority samples to balance classes:\n",
        "\n",
        "$$\n",
        "n_{majority}^{new} \\approx n_{minority}^{original} \\quad \\text{or some ratio } r\n",
        "$$\n",
        "\n",
        "Prevents model from being biased toward majority class, improving rare class detection.\n",
        "\n",
        "3. **Up-Down Weighting (Class Weighting)**\n",
        "\n",
        "Assign higher weight $w_i$ to minority class samples during training:\n",
        "\n",
        "$$\n",
        "w_i =\n",
        "\\begin{cases}\n",
        "\\frac{n}{2 \\cdot n_{minority}} & \\text{if } y_i = 1 \\\\\n",
        "\\frac{n}{2 \\cdot n_{majority}} & \\text{if } y_i = 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Loss function becomes weighted:\n",
        "\n",
        "$$\n",
        "\\text{Weighted Loss} = \\sum_{i=1}^{n} w_i \\cdot \\ell(y_i, \\hat{p}_i)\n",
        "$$\n",
        "\n",
        "Model penalizes misclassification of minority class more means improves detection.\n",
        "\n",
        "#### Fitting\n",
        "\n",
        "**1. Hosmer-Lemeshow Test**\n",
        "\n",
        "The Hosmer-Lemeshow test evaluates how well the predicted probabilities from a binary logistic regression model fit the observed outcomes.\n",
        "\n",
        "1. Sort the predicted probabilities and divide them into $g$ groups (commonly $g=10$ deciles).  \n",
        "2. For each group $j$, calculate the observed ($O_j$) and expected ($E_j$) number of events (positives).  \n",
        "3. Compute the test statistic:\n",
        "\n",
        "$$\n",
        "C = \\sum_{j=1}^{g} \\frac{(O_j - E_j)^2}{E_j (1 - E_j / n_j)}\n",
        "$$\n",
        "\n",
        "- $n_j$: number of observations in group $j$  \n",
        "- Under the null hypothesis of good fit, $C$ approximately follows a $\\chi^2$ distribution with $g-2$ degrees of freedom.  \n",
        "\n",
        "**Interpretation:**  \n",
        "- $p > 0.05$: model fits well  \n",
        "- $p < 0.05$: poor fit  \n",
        "\n",
        "\n",
        "**2. Deviance / Likelihood Ratio Test**\n",
        "\n",
        "Compares the fitted model to a baseline (intercept-only) model to assess improvement in fit.\n",
        "\n",
        "$$\n",
        "G = -2 \\big( \\ell_0 - \\ell_1 \\big)\n",
        "$$\n",
        "\n",
        "- $\\ell_0$: log-likelihood of the intercept-only model  \n",
        "- $\\ell_1$: log-likelihood of the fitted model  \n",
        "- $G \\sim \\chi^2_{df}$ where $df = \\text{number of predictors}$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Large $G$ and small $p$-value indicate that the fitted model significantly improves fit over the null model.\n",
        "\n",
        "**3. Residual Analysis**\n",
        "\n",
        "Residuals are used to detect lack-of-fit or outliers.\n",
        "\n",
        "**Deviance residuals:**\n",
        "\n",
        "$$\n",
        "r_i^{(D)} = \\text{sign}(y_i - \\hat{p}_i) \\sqrt{-2 \\Big[ y_i \\ln(\\hat{p}_i) + (1-y_i)\\ln(1-\\hat{p}_i) \\Big]}\n",
        "$$\n",
        "\n",
        "**Pearson residuals:**\n",
        "\n",
        "$$\n",
        "r_i^{(P)} = \\frac{y_i - \\hat{p}_i}{\\sqrt{\\hat{p}_i (1 - \\hat{p}_i)}}\n",
        "$$\n",
        "\n",
        "- Large absolute residuals indicate potential outliers or observations poorly fitted by the model.  \n",
        "\n",
        "#### Regularizing\n",
        "\n",
        "Regularizing helps prevent overfitting by penalizing large coefficient values in binary logistic regression.\n",
        "\n",
        "**L2 Regularization (Ridge)**\n",
        "\n",
        "Adds a penalty proportional to the square of the coefficients.\n",
        "\n",
        "$$\n",
        "\\text{Loss}_{\\text{Ridge}} = - \\ell(\\beta) + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\ell(\\beta)$: log-likelihood of the binary logistic regression model  \n",
        "- $\\beta_j$: coefficient of predictor $j$  \n",
        "- $p$: number of predictors  \n",
        "- $\\lambda \\ge 0$: regularization strength (hyperparameter) & chosen via cross-validation to optimize predictive performance.\n",
        "\n",
        "**Interpretation:**  \n",
        "- Shrinks coefficients towards zero.\n",
        "\n",
        "**L1 Regularization (Lasso)**\n",
        "\n",
        "Adds a penalty proportional to the absolute value of the coefficients.\n",
        "\n",
        "$$\n",
        "\\text{Loss}_{\\text{Lasso}} = - \\ell(\\beta) + \\lambda \\sum_{j=1}^{p} |\\beta_j|\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "- It can shrink some coefficients exactly to zero means automatic feature selection.\n",
        "\n",
        "Both L1 and L2 can be combined in **Elastic Net** regularization.  "
      ],
      "metadata": {
        "id": "Xh3VGFTMTlhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multinominal Logistic Regression Model"
      ],
      "metadata": {
        "id": "b-og4_4dTl9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model\n",
        "\n",
        "Multinomial logistic regression model is:\n",
        "\n",
        "$$\n",
        "p_{ik} = P(y_i = k \\mid x_i) = \\frac{\\exp(\\beta_{0k} + \\beta_{1k} x_i)}{\\sum_{j=1}^K \\exp(\\beta_{0j} + \\beta_{1j} x_i)},\n",
        "\\quad k = 1,2,\\dots,K\n",
        "$$\n",
        "\n",
        "- One category (say $K$) is chosen as the baseline/reference category and for this baseline, parameters are set to $\\beta_{0K} = 0, \\; \\beta_{1K} = 0$.  \n",
        "\n",
        "**Where:**\n",
        "- $y_i \\in \\{1,2,\\dots,K\\}$: multinomial dependent variable (outcome) for observation $i$  \n",
        "- $x_i$: independent variable (predictor) for observation $i$  \n",
        "- $\\beta_{0k}$: intercept for category $k$ relative to the baseline  \n",
        "- $\\beta_{1k}$: slope for category $k$ relative to the baseline  \n",
        "- $p_{ik}$: predicted probability that $y_i = k$ given $x_i$  \n",
        "\n",
        "Also for multiple predictors, the multinomial logistic regression model generalizes to:\n",
        "\n",
        "$$\n",
        "P(y_i = k \\mid \\mathbf{x}_i) = \\frac{\\exp(\\theta_k + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}_k)}{\\sum_{j=1}^{K} \\exp(\\theta_j + \\mathbf{x}_i^\\top \\boldsymbol{\\beta}_j)}, \\quad k = 1, \\dots, K\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\mathbf{x}_i = (x_{i1}, x_{i2}, \\dots, x_{ip})^\\top$ is a vector of $p$ predictors for observation $i$  \n",
        "- $\\boldsymbol{\\beta}_k = (\\beta_{k1}, \\beta_{k2}, \\dots, \\beta_{kp})^\\top$ is the coefficient vector for class $k$  \n",
        "- $\\theta_k$ is the intercept for class $k$  \n",
        "- $K$ is the total number of outcome categories  \n",
        "\n",
        "This formulation explicitly accounts for multiple predictors and allows each category to have its own set of coefficients.\n",
        "\n",
        "Instead of modeling $y_i$ directly, logistic regression models the log-odds (logit) and the model estimates $K-1$ log-odds equations relative to the baseline:\n",
        "\n",
        "$$\n",
        "\\ln\\left(\\frac{P(y_i = k \\mid x_i)}{P(y_i = K \\mid x_i)}\\right) = \\beta_{0k} + \\beta_{1k} x_i,\n",
        "\\quad k = 1,2,\\dots,K-1\n",
        "$$\n",
        "\n",
        "**While:**\n",
        "\n",
        "- **Known (from the data):** $x_i, y_i$ (observations, with $y_i \\in \\{1,2,\\dots,K\\}$).  \n",
        "- **Unknown but to be estimated:** $\\beta_{0k}, \\beta_{1k}$ for $k=1,\\dots,K-1$ (parameters of the multinomial logistic model).  \n",
        "- **Not directly known but assumed:** The probabilities $p_{ik}$, derived from the multinomial logistic function.  \n",
        "\n",
        "In multinomial logistic regression, parameters are estimated by **Maximum Likelihood Estimation (MLE)**.\n",
        "\n",
        "The MLE is:\n",
        "\n",
        "$$\n",
        "L(\\beta) = \\prod_{i=1}^n \\prod_{k=1}^K p_{ik}^{I(y_i = k)}\n",
        "$$\n",
        "\n",
        "where $I(y_i=k)$ is an indicator function that equals $1$ if observation $i$ belongs to category $k$, and $0$ otherwise.\n",
        "\n",
        "And the log-MLE is:\n",
        "\n",
        "$$\n",
        "\\ell(\\beta) = \\sum_{i=1}^n \\sum_{k=1}^K I(y_i = k) \\ln(p_{ik})\n",
        "$$\n",
        "\n",
        "- Estimators $\\hat{\\beta}_{0k}, \\hat{\\beta}_{1k}$ (for $k = 1,\\dots,K-1$) are obtained by maximizing $\\ell(\\beta)$.  \n",
        "- This gives the “best-fitting set of multinomial logistic functions” that separates the $K$ outcome classes.\n",
        "\n",
        "#### Performance\n",
        "\n",
        "**Cross-Validation**\n",
        "\n",
        "To estimate the generalization performance of the multinomial logistic regression model on unseen data.  \n",
        "\n",
        "**k-Fold Cross-Validation**\n",
        "\n",
        "1. Split the data into $k$ roughly equal folds (subsets): $D_1, D_2, \\dots, D_k$.  \n",
        "2. For each fold $j = 1, \\dots, k$:\n",
        "   - Train the model on the remaining $k-1$ folds: $D_{-j} = D \\setminus D_j$  \n",
        "   - Fit the model to obtain $\\hat{\\beta}_{0k}^{(-j)}, \\hat{\\beta}_{1k}^{(-j)}$ for $k=1,\\dots,K-1$  \n",
        "   - Predict on the left-out fold $D_j$:  \n",
        "$$\n",
        "\\hat{p}_{ik}^{(-j)} =\n",
        "\\frac{\\exp(\\hat{\\beta}_{0k}^{(-j)} + \\hat{\\beta}_{1k}^{(-j)} x_i)}\n",
        "{\\sum_{m=1}^K \\exp(\\hat{\\beta}_{0m}^{(-j)} + \\hat{\\beta}_{1m}^{(-j)} x_i)},\n",
        "\\quad i \\in D_j\n",
        "$$\n",
        "\n",
        "3. Compute the prediction error using a multiclass classification loss (e.g., Multinomial Log Loss, Accuracy, Macro-F1) for each fold.  \n",
        "\n",
        "- *Common choices are $k=5$ or $k=10$*  \n",
        "- *Leave-One-Out CV (LOOCV) is also a special case that means $k=n$, each observation is used as a single test case.*  \n",
        "\n",
        "Cross-validation gives an estimate of the expected performance on new/unseen data.  \n",
        "\n",
        "Lower multinomial log loss or higher accuracy/F1 indicates better generalization performance.  \n",
        "\n",
        "This method also helps detect overfitting — a model with very high training accuracy but much lower cross-validation accuracy is overfitting the training data.\n",
        "\n",
        "**via Accuracy**\n",
        "\n",
        "**Per-Class:**  \n",
        "Accuracy calculated for each class $k$ individually.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy}_k = \\frac{TP_k + TN_k}{TP_k + TN_k + FP_k + FN_k}, \\quad k = 1,\\dots,K\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $TP_k$: true positives for class $k$  \n",
        "- $TN_k$: true negatives for class $k$  \n",
        "- $FP_k$: false positives for class $k$  \n",
        "- $FN_k$: false negatives for class $k$  \n",
        "\n",
        "**Micro:**  \n",
        "Proportion of all correctly classified observations.\n",
        "\n",
        "$$\n",
        "\\text{Micro-Accuracy} = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}(\\hat{y}_i = y_i)\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $n$: total number of observations  \n",
        "- $\\hat{y}_i = \\arg\\max_{k \\in \\{1,\\dots,K\\}} \\hat{p}_{ik}$ (predicted class)  \n",
        "- $y_i$: true class  \n",
        "\n",
        "**Macro:**  \n",
        "Average of per-class accuracies.\n",
        "\n",
        "$$\n",
        "\\text{Macro-Accuracy} = \\frac{1}{K} \\sum_{k=1}^K \\text{Accuracy}_k\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $K$: number of classes  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Higher percentage means the model correctly classifies more observations.  \n",
        "\n",
        "**via Precision**\n",
        "\n",
        "**Per-Class:**\n",
        "\n",
        "For each class $k$ individually.\n",
        "\n",
        "$$\n",
        "\\text{Precision}_k = \\frac{TP_k}{TP_k + FP_k}, \\quad k=1,\\dots,K\n",
        "$$  \n",
        "\n",
        "**Macro:**\n",
        "\n",
        "Average over all classes.  \n",
        "\n",
        "$$\n",
        "\\text{Macro-Precision} = \\frac{1}{K} \\sum_{k=1}^K \\text{Precision}_k\n",
        "$$  \n",
        "\n",
        "**Micro:**\n",
        "\n",
        "Global TP/FP across all classes.  \n",
        "\n",
        "$$\n",
        "\\text{Micro-Precision} = \\frac{\\sum_{k=1}^K TP_k}{\\sum_{k=1}^K (TP_k + FP_k)}\n",
        "$$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Higher percentage means the model detects more of the positive cases.  \n",
        "\n",
        "**via Recall (Sensitivity)**\n",
        "\n",
        "**Per-Class:**  \n",
        "For each class $k$ individually.\n",
        "\n",
        "$$\n",
        "\\text{Recall}_k = \\frac{TP_k}{TP_k + FN_k}, \\quad k=1,\\dots,K\n",
        "$$  \n",
        "\n",
        "**Macro:**  \n",
        "Average over all classes.\n",
        "\n",
        "$$\n",
        "\\text{Macro-Recall} = \\frac{1}{K} \\sum_{k=1}^K \\text{Recall}_k\n",
        "$$  \n",
        "\n",
        "**Micro:**  \n",
        "Global TP/FN across all classes.\n",
        "\n",
        "$$\n",
        "\\text{Micro-Recall} = \\frac{\\sum_{k=1}^K TP_k}{\\sum_{k=1}^K (TP_k + FN_k)}\n",
        "$$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Higher percentage means the model detects more of the positive cases.\n",
        "\n",
        "**via Specificity**\n",
        "\n",
        "**Per-Class:**  \n",
        "For each class $k$ individually.\n",
        "\n",
        "$$\n",
        "\\text{Specificity}_k = \\frac{TN_k}{TN_k + FP_k}, \\quad k=1,\\dots,K\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $TN_k$: True Negatives for class $k$  \n",
        "- $FP_k$: False Positives for class $k$  \n",
        "\n",
        "**Macro:**  \n",
        "Average over all classes.\n",
        "\n",
        "$$\n",
        "\\text{Macro-Specificity} = \\frac{1}{K} \\sum_{k=1}^K \\text{Specificity}_k\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $K$: number of classes  \n",
        "\n",
        "**Micro:**  \n",
        "Global TN/FP across all classes.\n",
        "\n",
        "$$\n",
        "\\text{Micro-Specificity} = \\frac{\\sum_{k=1}^K TN_k}{\\sum_{k=1}^K (TN_k + FP_k)}\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $TN_k$: True Negatives for class $k$  \n",
        "- $FP_k$: False Positives for class $k$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Higher percentage means the model correctly rejects more negative cases, avoiding false alarms.\n",
        "\n",
        "**via F1-score**\n",
        "\n",
        "**Per-Class:**  \n",
        "For each class $k$ individually.\n",
        "\n",
        "$$\n",
        "F1_k = \\frac{2 \\cdot \\text{Precision}_k \\cdot \\text{Recall}_k}{\\text{Precision}_k + \\text{Recall}_k}, \\quad k=1,\\dots,K\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $\\text{Precision}_k = \\frac{TP_k}{TP_k + FP_k}$  \n",
        "- $\\text{Recall}_k = \\frac{TP_k}{TP_k + FN_k}$  \n",
        "- $TP_k$: True Positives for class $k$  \n",
        "- $FP_k$: False Positives for class $k$  \n",
        "- $FN_k$: False Negatives for class $k$  \n",
        "\n",
        "**Macro:**  \n",
        "Average over all classes.\n",
        "\n",
        "$$\n",
        "\\text{Macro-F1} = \\frac{1}{K} \\sum_{k=1}^K F1_k\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $K$: number of classes  \n",
        "\n",
        "**Micro:**  \n",
        "Global TP/FP/FN across all classes.\n",
        "\n",
        "$$\n",
        "\\text{Micro-F1} = \\frac{2 \\cdot \\sum_{k=1}^K TP_k}{2 \\cdot \\sum_{k=1}^K TP_k + \\sum_{k=1}^K (FP_k + FN_k)}\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $TP_k$: True Positives for class $k$  \n",
        "- $FP_k$: False Positives for class $k$  \n",
        "- $FN_k$: False Negatives for class $k$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Balances false positives and false negatives to get higher percentage indicates better balanced performance.\n",
        "\n",
        "**via ROC To AUC**\n",
        "\n",
        "For each class $k$:  \n",
        "\n",
        "- True Positive Rate (TPR) = $\\frac{TP_k}{TP_k + FN_k}$  \n",
        "- False Positive Rate (FPR) = $\\frac{FP_k}{FP_k + TN_k}$  \n",
        "\n",
        "- Compute AUC$_k$ for each class  \n",
        "- **Macro-AUC:** average over classes  \n",
        "- **Micro-AUC:** global TPR/FPR across all classes  \n",
        "\n",
        "**Interpretation:**  \n",
        "- AUC closer to 1 = better discrimination between class $k$ vs rest.\n",
        "\n",
        "**via Log Loss (Cross-Entropy Loss)**\n",
        "\n",
        "Penalizes confident but wrong predictions.\n",
        "\n",
        "Multinomial cross-entropy:\n",
        "\n",
        "$$\n",
        "\\text{LogLoss} = -\\frac{1}{n} \\sum_{i=1}^n \\sum_{k=1}^K \\mathbf{1}(y_i = k) \\ln(\\hat{p}_{ik})\n",
        "$$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Higher log loss means worse predictions; heavily penalizes confident incorrect predictions.\n",
        "\n",
        "**via Cohen's Kappa**\n",
        "\n",
        "Cohen's Kappa measures the agreement between predicted and true classes, adjusted for chance agreement.\n",
        "\n",
        "$$\n",
        "\\kappa = \\frac{p_o - p_e}{1 - p_e}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $p_o = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}(\\hat{y}_i = y_i)$ : observed agreement (accuracy)  \n",
        "- $p_e = \\sum_{k=1}^{K} p_{k}^{\\text{pred}} \\cdot p_{k}^{\\text{true}}$ : expected agreement by chance  \n",
        "  - $p_{k}^{\\text{pred}}$: proportion of predictions in class $k$  \n",
        "  - $p_{k}^{\\text{true}}$: proportion of true instances in class $k$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- $\\kappa = 1$: perfect agreement  \n",
        "- $\\kappa = 0$: agreement equivalent to chance  \n",
        "- $\\kappa < 0$: worse than chance  \n",
        "\n",
        "**via Top-K Accuracy**\n",
        "\n",
        "Top-K Accuracy evaluates whether the true class is among the top $K$ predicted probabilities.\n",
        "\n",
        "$$\n",
        "\\text{Top-K Accuracy} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\Big(y_i \\in \\text{TopK}(\\hat{\\mathbf{p}}_i)\\Big)\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $y_i$: true class for observation $i$  \n",
        "- $\\hat{\\mathbf{p}}_i = (\\hat{p}_{i1}, \\dots, \\hat{p}_{iK})$: predicted probability vector for observation $i$  \n",
        "- $\\text{TopK}(\\hat{\\mathbf{p}}_i)$: set of classes corresponding to the $K$ highest predicted probabilities for observation $i$  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Top-1 Accuracy = standard accuracy  \n",
        "- Top-K Accuracy > Top-1 captures model performance in multi-class ranking\n",
        "\n",
        "#### Prediction\n",
        "\n",
        "Multinomial logistic regression model for prediction is:\n",
        "\n",
        "$$\n",
        "\\hat{p}_{new,k} = \\frac{\\exp(\\hat{\\beta}_{0k} + \\hat{\\beta}_{1k} x_{new})}{\\sum_{j=1}^K \\exp(\\hat{\\beta}_{0j} + \\hat{\\beta}_{1j} x_{new})},\n",
        "\\quad k = 1,2,\\dots,K\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $\\hat{\\beta}_{0k}$: estimated intercept for class $k$  \n",
        "- $\\hat{\\beta}_{1k}$: estimated slope coefficient for class $k$  \n",
        "- $x_{new}$: new value of the predictor variable  \n",
        "- $\\hat{p}_{new,k}$: predicted probability that $y=k$ for the new observation  \n",
        "\n",
        "To estimate the uncertainty of the predicted probability $\\hat{p}_{new,k}$ at $x_{new}$, a **confidence interval** can be constructed using the standard error of the logit (log-odds) for each class relative to the baseline:\n",
        "\n",
        "1. Compute the logit of the predicted probability relative to the baseline class $K$:\n",
        "\n",
        "$$\n",
        "\\hat{\\text{logit}}_{new,k} = \\hat{\\beta}_{0k} + \\hat{\\beta}_{1k} x_{new}, \\quad k = 1, \\dots, K-1\n",
        "$$\n",
        "\n",
        "2. Construct a CI for the logit:\n",
        "\n",
        "$$\n",
        "\\hat{\\text{logit}}_{new,k} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\text{logit}}_{new,k})\n",
        "$$\n",
        "\n",
        "While\n",
        "\n",
        "$$\n",
        "SE(\\hat{\\text{logit}}_{new,k}) = \\sqrt{x_{new}^\\top \\, \\text{Cov}(\\hat{\\beta}_k) \\, x_{new}}, \\quad k = 1, \\dots, K-1\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $SE(\\hat{\\text{logit}}_{new,k})$: standard error of the predicted logit for class $k$  \n",
        "- $z_{\\alpha/2}$: critical value from the standard normal distribution (e.g., 1.96 for 95% CI)  \n",
        "- $x_{new}$: predictor vector for the new observation (including intercept)  \n",
        "- $\\text{Cov}(\\hat{\\beta}_k)$: estimated covariance matrix of the coefficients for category $k$  \n",
        "- $K$: total number of categories; category $K$ is chosen as the baseline  \n",
        "\n",
        "3. Transform back to probability scale using the softmax function:\n",
        "\n",
        "$$\n",
        "\\hat{p}_{\\text{new},k} =\n",
        "\\frac{\n",
        "\\exp\\big(\\hat{\\beta}_{0k} + \\hat{\\beta}_{1k} x_{\\text{new}}\\big)\n",
        "}{\n",
        "\\sum_{j=1}^{K} \\exp\\big(\\hat{\\beta}_{0j} + \\hat{\\beta}_{1j} x_{\\text{new}}\\big)\n",
        "}, \\quad k = 1, \\dots, K\n",
        "$$\n",
        "\n",
        "\n",
        "CI gives a range in which the true probability for each class is likely to lie.  \n",
        "\n",
        "Unlike linear regression, there is no standard **prediction interval** for a single observation, because the response is categorical.  \n",
        "\n",
        "**Extrapolation** occurs when $x_{new}$ is outside the range of observed $x_i$; predicted probabilities may be unreliable.\n",
        "\n",
        "#### Lifting\n",
        "\n",
        "Measures the effectiveness of a predictive model compared to random guessing especially in rare classess.  \n",
        "\n",
        "**Per-Class Lift:**\n",
        "\n",
        "For class $k$:\n",
        "\n",
        "$$\n",
        "\\text{Lift}_k = \\frac{\\text{Proportion of class } k \\text{ in model-selected group}}{\\text{Proportion of class } k \\text{ in entire population}}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- Model-selected group: top decile or bin of observations with highest predicted probability $\\hat{p}_{ik}$ for class $k$  \n",
        "- Entire population: all $n$ observations  \n",
        "- $k = 1, 2, $\\dots$, K$  \n",
        "\n",
        "**Interpretation:**  \n",
        "\n",
        "- $\\text{Lift}_k > 1$ means model is better than random at identifying class $k$.  \n",
        "- $\\text{Lift}_k = 1$ means model performs no better than random.  \n",
        "\n",
        "**Macro-Lift:** Average lift across all classes.\n",
        "\n",
        "$$\n",
        "\\text{Macro-Lift} = \\frac{1}{K} \\sum_{k=1}^K \\text{Lift}_k\n",
        "$$\n",
        "\n",
        "**Micro-Lift:** Weighted lift across all classes based on class frequencies.\n",
        "\n",
        "$$\n",
        "\\text{Micro-Lift} = \\frac{\\sum_{k=1}^K n_k \\cdot \\text{Lift}_k}{\\sum_{k=1}^K n_k}\n",
        "$$\n",
        "\n",
        "When the positive class is rare, standard models may underperform and the techniques like oversampling, undersampling & weighting can help increase the model's ability to identify the rare class, improving the lift metrics.\n",
        "\n",
        "1. **Oversampling (Synthetic or Duplicate Sampling)**\n",
        "\n",
        "Increase the number of minority class samples for class $k$.\n",
        "\n",
        "$$\n",
        "n_{k}^{new} > n_{k}^{original}\n",
        "$$\n",
        "\n",
        "By synthetic generation (SMOTE) for each minority sample $x_i$, generate a new sample along the line connecting $x_i$ to one of its $k$ nearest neighbors $x_{nn}$:\n",
        "\n",
        "$$\n",
        "x_{new} = x_i + \\lambda \\cdot (x_{nn} - x_i), \\quad \\lambda \\sim U(0,1)\n",
        "$$\n",
        "\n",
        "2. **Undersampling (Majority Reduction)**\n",
        "\n",
        "Reduce the number of majority class samples.\n",
        "\n",
        "$$\n",
        "n_{majority}^{new} < n_{majority}^{original}\n",
        "$$\n",
        "\n",
        "Randomly select a subset of majority samples to balance classes:\n",
        "\n",
        "$$\n",
        "n_{majority}^{new} \\approx n_{minority}^{original} \\quad \\text{or some ratio } r\n",
        "$$\n",
        "\n",
        "3. **Up-Down Weighting (Class Weighting)**\n",
        "\n",
        "Assign higher weight $w_i$ to minority class samples during training.\n",
        "\n",
        "$$\n",
        "w_i =\n",
        "\\begin{cases}\n",
        "\\frac{n}{K \\cdot n_k} & \\text{if } y_i = k \\\\\n",
        "\\frac{n}{K \\cdot n_j} & \\text{if } y_i = j \\neq k\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Loss function becomes weighted:\n",
        "\n",
        "$$\n",
        "\\text{Weighted Loss} = \\sum_{i=1}^{n} w_i \\cdot \\ell(y_i, \\hat{p}_{ik})\n",
        "$$\n",
        "\n",
        "Model penalizes misclassification of minority class more means improves detection.\n",
        "\n",
        "#### Fitting\n",
        "\n",
        "**Deviance & Pearson Chi-Square Tests**\n",
        "\n",
        "**Deviance:** Measures the discrepancy between the observed data and the model-predicted probabilities.\n",
        "\n",
        "$$\n",
        "D = 2 \\sum_{i=1}^n \\sum_{k=1}^K I(y_i=k) \\ln \\frac{I(y_i=k)}{\\hat{p}_{ik}}\n",
        "$$\n",
        "\n",
        "**Pearson Chi-Square:** Compares observed and expected counts in each category.\n",
        "\n",
        "$$\n",
        "X^2 = \\sum_{i=1}^n \\sum_{k=1}^K \\frac{(I(y_i=k) - \\hat{p}_{ik})^2}{\\hat{p}_{ik}}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $n$ = number of observations  \n",
        "- $K$ = number of outcome categories  \n",
        "- $y_i \\in \\{1, \\dots, K\\}$ = observed class for observation $i$  \n",
        "- $\\hat{p}_{ik}$ = predicted probability that $y_i = k$  \n",
        "- $I(y_i=k)$ = indicator function, $1$ if $y_i=k$, $0$ otherwise  \n",
        "\n",
        "The test statistic can be compared to a chi-square distribution with degrees of freedom:\n",
        "\n",
        "$$\n",
        "df = n - (K-1) \\cdot p\n",
        "$$\n",
        "\n",
        "where $p$ is the number of predictors. Large values of $D$ or $X^2$ indicate poor model fit.\n",
        "\n",
        "**Likelihood Ratio Test (LRT)**\n",
        "\n",
        "The LRT compares a nested model (simpler) with a full model (more parameters) to evaluate whether additional predictors significantly improve the fit:\n",
        "\n",
        "$$\n",
        "G^2 = -2 \\left( \\ell_0 - \\ell_1 \\right)\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $\\ell_0$ = log-likelihood of the nested (smaller) model  \n",
        "- $\\ell_1$ = log-likelihood of the full model  \n",
        "\n",
        "Degrees of freedom:  \n",
        "\n",
        "$$\n",
        "df = \\text{number of additional parameters in the full model}\n",
        "$$\n",
        "\n",
        "A large $G^2$ value indicates that the full model significantly improves the fit compared to the nested model.\n",
        "\n",
        "**Pseudo R² Measures**\n",
        "\n",
        "Since traditional R² is not defined for logistic models, several pseudo R² metrics are used to assess the goodness-of-fit:\n",
        "\n",
        "**McFadden R²**:\n",
        "$$\n",
        "R^2_\\text{McFadden} = 1 - \\frac{\\ell_1}{\\ell_0}\n",
        "$$\n",
        "\n",
        "**Cox & Snell R²**:\n",
        "$$\n",
        "R^2_\\text{Cox-Snell} = 1 - \\left(\\frac{L_0}{L_1}\\right)^{2/n}\n",
        "$$\n",
        "\n",
        "**Nagelkerke R²** (adjusted Cox & Snell):\n",
        "$$\n",
        "R^2_\\text{Nagelkerke} = \\frac{R^2_\\text{Cox-Snell}}{1 - L_0^{2/n}}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $L_0 = \\exp(\\ell_0)$ = likelihood of the intercept-only model  \n",
        "- $L_1 = \\exp(\\ell_1)$ = likelihood of the fitted model  \n",
        "- $n$ = number of observations  \n",
        "\n",
        "Higher pseudo R² values indicate better model fit, although they do not have a direct interpretation as variance explained like in linear regression.\n",
        "\n",
        "#### Regularizing\n",
        "\n",
        "Regularizing is used to prevent overfitting by penalizing large coefficients.\n",
        "\n",
        "**Ridge (L2) Regularization**\n",
        "\n",
        "Ridge penalizes the sum of squared coefficients.\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\beta) = - \\sum_{i=1}^{n} \\sum_{k=1}^{K} I(y_i=k) \\ln(\\hat{p}_{ik}) + \\lambda \\sum_{k=1}^{K-1} \\sum_{j=0}^{p} \\beta_{jk}^2\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $n$ = number of observations  \n",
        "- $K$ = number of classes  \n",
        "- $p$ = number of predictors  \n",
        "- $\\beta_{jk}$ = coefficient for predictor $j$ and class $k$  \n",
        "- $\\lambda$ = regularization strength (hyperparameter) & chosen via cross-validation to optimize predictive performance.\n",
        "- $\\hat{p}_{ik}$ = predicted probability for observation $i$ in class $k$  \n",
        "- $I(y_i=k)$ = indicator function, $1$ if $y_i=k$, $0$ otherwise  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Shrinks coefficients towards zero.\n",
        "\n",
        "**Lasso (L1) Regularization**\n",
        "\n",
        "Lasso penalizes the sum of absolute coefficients.\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\beta) = - \\sum_{i=1}^{n} \\sum_{k=1}^{K} I(y_i=k) \\ln(\\hat{p}_{ik}) + \\lambda \\sum_{k=1}^{K-1} \\sum_{j=0}^{p} |\\beta_{jk}|\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "- It can shrink some coefficients exactly to zero means automatic feature selection.\n",
        "\n",
        "Both L1 and L2 can be combined in **Elastic Net** regularization."
      ],
      "metadata": {
        "id": "kU3cDnbWToc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordinal Logistic Regression Model"
      ],
      "metadata": {
        "id": "4mftWfrhw7Rr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model\n",
        "\n",
        "Ordinal logistic regression model is:\n",
        "\n",
        "$$\n",
        "\\text{logit}\\big(P(y_i \\le k \\mid x_i)\\big) = \\ln\\left(\\frac{P(y_i \\le k \\mid x_i)}{P(y_i > k \\mid x_i)}\\right) = \\theta_k - \\beta x_i, \\quad k = 1,2,\\dots,K-1\n",
        "$$\n",
        "\n",
        "- $\\theta_k$: intercept (cutpoint) for threshold $k$  \n",
        "- $\\beta$: slope coefficient for predictor $x_i$, common across all thresholds (proportional odds assumption)  \n",
        "- $y_i$: ordinal outcome for observation $i$  \n",
        "- $x_i$: independent variable  \n",
        "\n",
        "Also for multiple predictors, the ordinal logistic regression model generalizes to:\n",
        "\n",
        "$$\n",
        "\\text{logit}\\big(P(y_i \\le k \\mid \\mathbf{x}_i)\\big) = \\theta_k - \\mathbf{x}_i^\\top \\boldsymbol{\\beta}, \\quad k = 1, \\dots, K-1\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\mathbf{x}_i = (x_{i1}, x_{i2}, \\dots, x_{ip})^\\top$ is a vector of $p$ predictors for observation $i$  \n",
        "- $\\boldsymbol{\\beta} = (\\beta_1, \\beta_2, \\dots, \\beta_p)^\\top$ is the coefficient vector (common across thresholds, proportional odds assumption)  \n",
        "- $\\theta_k$ is the intercept (cutpoint) for threshold $k$  \n",
        "\n",
        "This explicitly accounts for multiple predictors while maintaining the proportional odds assumption.\n",
        "\n",
        "**Category probabilities** are obtained as:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(y_i = 1 \\mid x_i) &= \\text{logit}^{-1}(\\theta_1 - \\beta x_i) \\\\\n",
        "P(y_i = k \\mid x_i) &= \\text{logit}^{-1}(\\theta_k - \\beta x_i) - \\text{logit}^{-1}(\\theta_{k-1} - \\beta x_i), \\quad k = 2,\\dots,K-1 \\\\\n",
        "P(y_i = K \\mid x_i) &= 1 - \\text{logit}^{-1}(\\theta_{K-1} - \\beta x_i)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "**Maximum Likelihood Estimation (MLE)** is used to estimate the parameters:\n",
        "\n",
        "$$\n",
        "L(\\theta, \\beta) = \\prod_{i=1}^n \\prod_{k=1}^K P(y_i = k \\mid x_i)\n",
        "$$\n",
        "\n",
        "Log-likelihood function:\n",
        "\n",
        "$$\n",
        "\\ell(\\theta, \\beta) = \\sum_{i=1}^n \\sum_{k=1}^K I(y_i = k) \\ln P(y_i = k \\mid x_i)\n",
        "$$\n",
        "\n",
        "Estimators $\\hat{\\theta}_k$ and $\\hat{\\beta}$ are obtained by maximizing $\\ell(\\theta, \\beta)$.\n",
        "\n",
        "#### Performance\n",
        "\n",
        "**Cross-Validation**\n",
        "\n",
        "To estimate the generalization performance of the ordinal logistic regression model on unseen data.  \n",
        "\n",
        "**k-Fold Cross-Validation**\n",
        "\n",
        "1. Split the data into $k$ roughly equal folds (subsets): $D_1, D_2, \\dots, D_k$.  \n",
        "2. For each fold $j = 1, \\dots, k$:\n",
        "   - Train the model on the remaining $k-1$ folds: $D_{-j} = D \\setminus D_j$  \n",
        "   - Fit the model to obtain $\\hat{\\theta}_k^{(-j)}, \\hat{\\beta}^{(-j)}$ for $k=1,\\dots,K-1$  \n",
        "   - Predict cumulative probabilities on the left-out fold $D_j$:  \n",
        "$$\n",
        "\\hat{P}(y_i \\le k \\mid x_i)^{(-j)} = \\text{logit}^{-1}(\\hat{\\theta}_k^{(-j)} - \\hat{\\beta}^{(-j)} x_i), \\quad i \\in D_j\n",
        "$$\n",
        "   - Obtain category probabilities:  \n",
        "$$\n",
        "\\hat{P}(y_i = 1 \\mid x_i)^{(-j)} = \\hat{P}(y_i \\le 1 \\mid x_i)^{(-j)}, \\quad\n",
        "\\hat{P}(y_i = k \\mid x_i)^{(-j)} = \\hat{P}(y_i \\le k \\mid x_i)^{(-j)} - \\hat{P}(y_i \\le k-1 \\mid x_i)^{(-j)}, \\quad k=2,\\dots,K-1\n",
        "$$\n",
        "$$\n",
        "\\hat{P}(y_i = K \\mid x_i)^{(-j)} = 1 - \\hat{P}(y_i \\le K-1 \\mid x_i)^{(-j)}\n",
        "$$\n",
        "\n",
        "3. Compute prediction error using ordinal-appropriate metrics (e.g., accuracy, macro-F1, or ordinal log loss) for each fold.  \n",
        "\n",
        "- *Common choices are $k=5$ or $k=10$*  \n",
        "- *Leave-One-Out CV (LOOCV) is a special case where $k=n$.*  \n",
        "\n",
        "Cross-validation provides an estimate of expected performance on new/unseen data.  \n",
        "\n",
        "Lower log loss or higher accuracy indicates better generalization performance.  \n",
        "\n",
        "**Log-Loss**\n",
        "\n",
        "Log-loss measures the uncertainty of predictions by penalizing incorrect classifications.  \n",
        "\n",
        "For $n$ observations and $K$ categories:\n",
        "\n",
        "$$\n",
        "\\text{LogLoss} = - \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{k=1}^{K} I(y_i = k) \\cdot \\log(\\hat{p}_{ik})\n",
        "$$\n",
        "\n",
        "- $I(y_i=k)$: indicator function (1 if true, 0 otherwise)  \n",
        "- $\\hat{p}_{ik}$: predicted probability that observation $i$ belongs to class $k$   \n",
        "\n",
        "**Mean Absolute Error (MAE)**\n",
        "\n",
        "MAE measures the average magnitude of errors between predicted and true categories.\n",
        "\n",
        "$$\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} | y_i - \\hat{y}_i |\n",
        "$$\n",
        "\n",
        "- $y_i$: true ordinal class (numeric)  \n",
        "- $\\hat{y}_i$: predicted ordinal class (numeric)  \n",
        "\n",
        "**Quadratic Weighted Kappa (QWK)**\n",
        "\n",
        "QWK penalizes larger disagreements more heavily using quadratic weights.\n",
        "\n",
        "$$\n",
        "w_{ij} = \\frac{(i-j)^2}{(K-1)^2}\n",
        "$$\n",
        "\n",
        "Then:\n",
        "\n",
        "$$\n",
        "\\kappa_{QW} = 1 - \\frac{\\sum_{i=1}^{K}\\sum_{j=1}^{K} w_{ij} O_{ij}}{\\sum_{i=1}^{K}\\sum_{j=1}^{K} w_{ij} E_{ij}}\n",
        "$$\n",
        "\n",
        "**Rank Correlation Measures**\n",
        "\n",
        "Ordinal predictions can also be evaluated using rank correlation metrics.\n",
        "\n",
        "- **Kendall’s Tau**:\n",
        "\n",
        "$$\n",
        "\\tau = \\frac{(C - D)}{\\tfrac{1}{2} n (n-1)}\n",
        "$$\n",
        "\n",
        "where $C$ = number of concordant pairs, $D$ = number of discordant pairs.  \n",
        "\n",
        "- **Somers’ D** (asymmetric measure, prediction vs. true labels):\n",
        "\n",
        "$$\n",
        "D_{yx} = \\frac{C - D}{C + D + T_y}\n",
        "$$\n",
        "\n",
        "where $T_y$ = number of ties in the true variable.  \n",
        "\n",
        "- **Concordance Index (C-index):**\n",
        "\n",
        "$$\n",
        "C = \\frac{\\text{Number of concordant pairs} + 0.5 \\times \\text{Number of ties}}{\\text{Total comparable pairs}}\n",
        "$$\n",
        "\n",
        "#### Prediction\n",
        "\n",
        "Ordinal logistic regression model for prediction is based on cumulative probabilities.\n",
        "\n",
        "$$\n",
        "\\hat{P}(y \\le k \\mid x_{\\text{new}}) = \\frac{1}{1 + \\exp\\!\\big(-(\\hat{\\theta}_k - \\hat{\\beta}^\\top x_{\\text{new}})\\big)},\n",
        "\\quad k = 1,2,\\dots,K-1\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $\\hat{\\theta}_k$: estimated threshold (cutpoint) for category $k$  \n",
        "- $\\hat{\\beta}$: estimated slope coefficient vector (common across categories)  \n",
        "- $x_{\\text{new}}$: predictor vector for the new observation  \n",
        "- $\\hat{P}(y \\le k \\mid x_{\\text{new}})$: predicted cumulative probability up to category $k$  \n",
        "\n",
        "The category-specific probabilities are obtained by differencing cumulative probabilities:\n",
        "\n",
        "$$\n",
        "\\hat{p}_{\\text{new},1} = \\hat{P}(y \\le 1 \\mid x_{\\text{new}})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{p}_{\\text{new},k} = \\hat{P}(y \\le k \\mid x_{\\text{new}}) - \\hat{P}(y \\le k-1 \\mid x_{\\text{new}}),\n",
        "\\quad k = 2, \\dots, K-1\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{p}_{\\text{new},K} = 1 - \\hat{P}(y \\le K-1 \\mid x_{\\text{new}})\n",
        "$$\n",
        "\n",
        "To estimate the uncertainty of the predicted cumulative logit at $x_{\\text{new}}$, a **confidence interval (CI)** can be constructed:\n",
        "\n",
        "1. Compute the cumulative logit for threshold $k$:\n",
        "\n",
        "$$\n",
        "\\hat{\\text{logit}}_{\\text{new},k} = \\hat{\\theta}_k - \\hat{\\beta}^\\top x_{\\text{new}}\n",
        "$$\n",
        "\n",
        "2. Construct a CI for the logit:\n",
        "\n",
        "$$\n",
        "\\hat{\\text{logit}}_{\\text{new},k} \\pm z_{\\alpha/2} \\cdot SE(\\hat{\\text{logit}}_{\\text{new},k})\n",
        "$$\n",
        "\n",
        "with\n",
        "\n",
        "$$\n",
        "SE(\\hat{\\text{logit}}_{\\text{new},k}) = \\sqrt{\n",
        "\\mathbf{x}_{\\text{new}}^\\top \\, \\text{Cov}(\\hat{\\boldsymbol{\\beta}}) \\, \\mathbf{x}_{\\text{new}}\n",
        "+ \\text{Var}(\\hat{\\theta}_k)\n",
        "+ 2 \\, \\mathbf{x}_{\\text{new}}^\\top \\, \\text{Cov}(\\hat{\\boldsymbol{\\beta}}, \\hat{\\theta}_k)\n",
        "}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $SE(\\hat{\\text{logit}}_{\\text{new},k})$: standard error of the cumulative logit at threshold $k$  \n",
        "- $z_{\\alpha/2}$: critical value from the standard normal distribution (e.g., 1.96 for 95% CI)  \n",
        "- $\\text{Cov}(\\hat{\\beta})$: estimated covariance matrix of slope coefficients  \n",
        "- $\\text{Cov}(\\hat{\\boldsymbol{\\beta}}, \\hat{\\theta}_k)$: estimated covariance vector between slopes and threshold $k$  \n",
        "- $\\text{Var}(\\hat{\\theta}_k)$: estimated variance of threshold $k$\n",
        "- $\\mathbf{x}_{\\text{new}}$: predictor vector for the new observation\n",
        "\n",
        "3. Transform the CI back to the probability scale using the logistic function.\n",
        "\n",
        "Unlike linear regression, there is no standard **prediction interval** for an individual observation.  \n",
        "\n",
        "**Extrapolation** occurs when $x_{\\text{new}}$ is outside the observed range; predicted probabilities may become unstable.\n",
        "\n",
        "#### Fitting\n",
        "\n",
        "**Deviance & Pearson Chi-Square Tests**\n",
        "\n",
        "**Deviance:** Measures the discrepancy between the observed data and the model-predicted probabilities.\n",
        "\n",
        "$$\n",
        "D = 2 \\sum_{i=1}^n \\sum_{k=1}^K I(y_i=k) \\ln \\frac{I(y_i=k)}{\\hat{p}_{ik}}\n",
        "$$\n",
        "\n",
        "**Pearson Chi-Square:** Compares observed and expected counts in each category.\n",
        "\n",
        "$$\n",
        "X^2 = \\sum_{i=1}^n \\sum_{k=1}^K \\frac{(I(y_i=k) - \\hat{p}_{ik})^2}{\\hat{p}_{ik}}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $n$ = number of observations  \n",
        "- $K$ = number of outcome categories  \n",
        "- $y_i \\in \\{1, \\dots, K\\}$ = observed class for observation $i$  \n",
        "- $\\hat{p}_{ik}$ = predicted probability that $y_i = k$, obtained from cumulative logits:  \n",
        "\n",
        "$$\n",
        "\\hat{p}_{ik} = \\hat{P}(y \\leq k \\mid x_i) - \\hat{P}(y \\leq k-1 \\mid x_i)\n",
        "$$\n",
        "\n",
        "- $I(y_i=k)$ = indicator function, $1$ if $y_i=k$, $0$ otherwise  \n",
        "\n",
        "The test statistic can be compared to a chi-square distribution with degrees of freedom:\n",
        "\n",
        "$$\n",
        "df = n - \\text{number of estimated parameters}\n",
        "$$\n",
        "\n",
        "Large values of $D$ or $X^2$ indicate poor model fit.\n",
        "\n",
        "**Likelihood Ratio Test (LRT)**\n",
        "\n",
        "The LRT compares a nested model (simpler) with a full model (more predictors) to evaluate whether additional predictors significantly improve the fit:\n",
        "\n",
        "$$\n",
        "G^2 = -2 \\left( \\ell_0 - \\ell_1 \\right)\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $\\ell_0$ = log-likelihood of the nested (smaller) model  \n",
        "- $\\ell_1$ = log-likelihood of the full model  \n",
        "\n",
        "Degrees of freedom:  \n",
        "\n",
        "$$\n",
        "df = \\text{number of additional parameters in the full model}\n",
        "$$\n",
        "\n",
        "A large $G^2$ value indicates that the full model significantly improves the fit compared to the nested model.\n",
        "\n",
        "**Pseudo R² Measures**\n",
        "\n",
        "Since traditional R² is not defined for logistic models, several pseudo R² metrics are used to assess the goodness-of-fit:\n",
        "\n",
        "**McFadden R²**:\n",
        "$$\n",
        "R^2_\\text{McFadden} = 1 - \\frac{\\ell_1}{\\ell_0}\n",
        "$$\n",
        "\n",
        "**Cox & Snell R²**:\n",
        "$$\n",
        "R^2_\\text{Cox-Snell} = 1 - \\left(\\frac{L_0}{L_1}\\right)^{2/n}\n",
        "$$\n",
        "\n",
        "**Nagelkerke R²** (adjusted Cox & Snell):\n",
        "$$\n",
        "R^2_\\text{Nagelkerke} = \\frac{R^2_\\text{Cox-Snell}}{1 - L_0^{2/n}}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $L_0 = \\exp(\\ell_0)$ = likelihood of the intercept-only model  \n",
        "- $L_1 = \\exp(\\ell_1)$ = likelihood of the fitted model  \n",
        "- $n$ = number of observations  \n",
        "\n",
        "Higher pseudo R² values indicate better model fit, although they do not have a direct interpretation as variance explained like in linear regression.\n",
        "\n",
        "#### Regularizing\n",
        "\n",
        "Regularizing is used to prevent overfitting by penalizing large coefficients.  \n",
        "\n",
        "In ordinal logistic regression, the loss is based on cumulative probabilities.\n",
        "\n",
        "**Ridge (L2) Regularization**\n",
        "\n",
        "Ridge penalizes the sum of squared coefficients.\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\beta) = - \\sum_{i=1}^{n}\n",
        "\\Bigg[\n",
        "\\sum_{k=1}^{K-1} I(y_i \\leq k) \\ln(\\hat{P}(y_i \\leq k \\mid x_i))\n",
        "+ I(y_i > k) \\ln(1 - \\hat{P}(y_i \\leq k \\mid x_i))\n",
        "\\Bigg]\n",
        "+ \\lambda \\sum_{j=1}^{p} \\beta_{j}^2\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $n$ = number of observations  \n",
        "- $K$ = number of ordered categories  \n",
        "- $p$ = number of predictors  \n",
        "- $\\beta_j$ = coefficient for predictor $j$ (common across thresholds)  \n",
        "- $\\lambda$ = regularization strength (hyperparameter), chosen via cross-validation  \n",
        "- $\\hat{P}(y_i \\leq k \\mid x_i)$ = predicted cumulative probability  \n",
        "- $I(\\cdot)$ = indicator function  \n",
        "\n",
        "**Interpretation:**  \n",
        "- Shrinks coefficients towards zero while keeping thresholds separate.\n",
        "\n",
        "**Lasso (L1) Regularization**\n",
        "\n",
        "Lasso penalizes the sum of absolute coefficients.\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\beta) = - \\sum_{i=1}^{n}\n",
        "\\Bigg[\n",
        "\\sum_{k=1}^{K-1} I(y_i \\leq k) \\ln(\\hat{P}(y_i \\leq k \\mid x_i))\n",
        "+ I(y_i > k) \\ln(1 - \\hat{P}(y_i \\leq k \\mid x_i))\n",
        "\\Bigg]\n",
        "+ \\lambda \\sum_{j=1}^{p} |\\beta_{j}|\n",
        "$$\n",
        "\n",
        "**Interpretation:**  \n",
        "- Can shrink some coefficients exactly to zero, performing automatic feature selection.\n",
        "\n",
        "Both L1 and L2 can be combined in **Elastic Net** regularization."
      ],
      "metadata": {
        "id": "bvqI26YCw-If"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELS IN PYTHON"
      ],
      "metadata": {
        "id": "5VOfNzdwaCzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELS FOR PREDICTION IN PYTHON"
      ],
      "metadata": {
        "id": "5syQMGAPzTLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOON"
      ],
      "metadata": {
        "id": "Ln-R4miFzub4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELS FOR CLASSIFICATION IN PYTHON"
      ],
      "metadata": {
        "id": "lbE17TiKzT6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOON"
      ],
      "metadata": {
        "id": "zuHL3w3MzWAo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}