{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5RpzXJEjOQuw",
        "pJ9-IRFGOtfz",
        "OMoiIYfBOyyd",
        "IBlcx6mXOo2b",
        "zQsocRDjO1z8",
        "Mi1Rw2q2O4LL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ARCHITECTURES"
      ],
      "metadata": {
        "id": "5RpzXJEjOQuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STRUCTURAL EQUATION MODEL"
      ],
      "metadata": {
        "id": "pJ9-IRFGOtfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specification\n",
        "\n",
        "SEM can estimate coefficients for both observed and latent variables.\n",
        "\n",
        "If the model includes latent factors, using OLS directly would be incorrect or incomplete, because OLS only accounts for relationships among observed variables.\n",
        "\n",
        "SEM provides more accurate estimates of βs by taking latent variables and measurement errors into account.\n",
        "\n",
        "In this direction, suppose we introduce a latent variable $\\eta$ representing a construct measured by observed indicators $X_1$ and $X_2$. Then the structural model becomes:\n",
        "\n",
        "$$\n",
        "Y = \\beta \\eta + \\zeta_Y\n",
        "$$\n",
        "\n",
        "and the measurement model for the latent variable $\\eta$ is:\n",
        "\n",
        "$$\n",
        "X_1 = \\lambda_1 \\eta + \\varepsilon_1\n",
        "$$\n",
        "\n",
        "$$\n",
        "X_2 = \\lambda_2 \\eta + \\varepsilon_2\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "- $\\beta$: regression coefficient of latent variable $\\eta$ on $Y$  \n",
        "- $\\lambda_1, \\lambda_2$: factor loadings of observed variables $X_1$ and $X_2$ on $\\eta$  \n",
        "- $\\zeta_Y$: structural error term for $Y$  \n",
        "- $\\varepsilon_1, \\varepsilon_2$: measurement errors of $X_1$ and $X_2$  \n",
        "\n",
        "The **path diagram** can be illustrated as:\n",
        "\n",
        "- Latent variable $\\eta$ → $Y$ (regression path)  \n",
        "- $\\eta$ → $X_1$, $\\eta$ → $X_2$ (factor loadings)  \n",
        "- Measurement errors $\\varepsilon_1$, $\\varepsilon_2$, $\\zeta_Y$ for each endogenous variable  \n",
        "\n",
        "This structure explicitly separates **measurement model** (how observed variables reflect latent constructs) from the **structural model** (how latent variables influence outcomes), which is the core strength of SEM.\n",
        "\n",
        "### Identification\n",
        "\n",
        "Suppose the latent variable $\\eta$ is measured by $X_1$ and $X_2$, and affects $Y$.  \n",
        "\n",
        "The covariance matrix of the observed variables can be written as:\n",
        "\n",
        "$$\n",
        "\\Sigma =\n",
        "\\begin{bmatrix}\n",
        "Var(X_1) & Cov(X_1, X_2) & Cov(X_1, Y) \\\\\n",
        "Cov(X_1, X_2) & Var(X_2) & Cov(X_2, Y) \\\\\n",
        "Cov(X_1, Y) & Cov(X_2, Y) & Var(Y)\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Unknown parameters now include:\n",
        "\n",
        "- Factor loadings: $\\lambda_1, \\lambda_2$  \n",
        "- Structural coefficient: $\\beta$  \n",
        "- Error variances: $Var(\\varepsilon_1), Var(\\varepsilon_2), Var(\\zeta_Y)$  \n",
        "\n",
        "So, total number of unknowns = 6  \n",
        "\n",
        "The number of independent elements in the covariance matrix is:\n",
        "\n",
        "$$\n",
        "n_{independent} = \\frac{n \\cdot (n+1)}{2}\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "- $n$ = number of observed variables  \n",
        "- $n_{independent}$ = number of independent pieces of information available for identification  \n",
        "\n",
        "Number of independent pieces of information in covariance matrix of 3 observed variables:\n",
        "\n",
        "$$\n",
        "\\frac{3 \\cdot (3+1)}{2} = 6\n",
        "$$\n",
        "\n",
        "- To scale the latent variable, we typically fix $Var(\\eta)=1$ or set one loading (e.g. $\\lambda_1=1$).\n",
        "- Since number of unknowns = number of independent pieces of information means **just-identified** (model can be solved exactly, no extra test possible)  \n",
        "- Adding more observed indicators for the latent variable or more latent constructs can make the model **over-identified**, which allows testing the model fit.  \n",
        "\n",
        "### Estimation\n",
        "\n",
        "With latent variable $\\eta$, estimation is based on **model-implied covariance matrix** rather than simple correlations.\n",
        "\n",
        "The model-implied covariances are:\n",
        "\n",
        "$$\n",
        "Cov(X_1, Y) = \\lambda_1 \\cdot \\beta \\cdot Var(\\eta)\n",
        "$$\n",
        "\n",
        "$$\n",
        "Cov(X_2, Y) = \\lambda_2 \\cdot \\beta \\cdot Var(\\eta)\n",
        "$$\n",
        "\n",
        "$$\n",
        "Cov(X_1, X_2) = \\lambda_1 \\cdot \\lambda_2 \\cdot Var(\\eta)\n",
        "$$\n",
        "\n",
        "$$\n",
        "Var(X_1) = \\lambda_1^2 \\cdot Var(\\eta) + Var(\\varepsilon_1)\n",
        "$$\n",
        "\n",
        "$$\n",
        "Var(X_2) = \\lambda_2^2 \\cdot Var(\\eta) + Var(\\varepsilon_2)\n",
        "$$\n",
        "\n",
        "$$\n",
        "Var(Y) = \\beta^2 \\cdot Var(\\eta) + Var(\\zeta_Y)\n",
        "$$\n",
        "\n",
        "The parameters ($\\lambda_1, \\lambda_2, \\beta, Var(\\varepsilon_1), Var(\\varepsilon_2), Var(\\zeta_Y)$) are estimated by **Maximum Likelihood (ML)**, minimizing the difference between the observed covariance matrix $\\Sigma$ and the model-implied covariance matrix $\\hat{\\Sigma}(\\theta)$:\n",
        "\n",
        "$$\n",
        "F_{ML}(\\theta) = \\log |\\hat{\\Sigma}(\\theta)| + \\text{tr}(\\Sigma \\hat{\\Sigma}^{-1}(\\theta)) - \\log |\\Sigma| - p\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "- $p$ = number of observed variables  \n",
        "- $\\theta$ = set of parameters  \n",
        "\n",
        "### Modification\n",
        "\n",
        "Suppose estimation gives:\n",
        "\n",
        "$$\n",
        "\\hat{\\beta} = 0.6, \\quad \\hat{\\lambda}_2 = 0.3\n",
        "$$\n",
        "\n",
        "But in the data we observe $Cov(X_2, Y)$ is much larger than predicted.  \n",
        "\n",
        "**Modification Index (MI)** may suggest freeing a currently fixed parameter, e.g., adding a direct path from $X_2$ to $Y$, or allowing $\\lambda_2$ to vary freely.\n",
        "\n",
        "Formally, if the ML fit function is  \n",
        "\n",
        "$$\n",
        "F_{ML}(\\theta) = \\log |\\hat{\\Sigma}(\\theta)| + \\text{tr}(\\Sigma \\hat{\\Sigma}^{-1}(\\theta)) - \\log |\\Sigma| - p,\n",
        "$$  \n",
        "\n",
        "then for a fixed parameter $\\theta_j$, the modification index is approximated as:\n",
        "\n",
        "$$\n",
        "MI_j = \\frac{\\left( \\frac{\\partial F}{\\partial \\theta_j} \\big|_{\\theta=\\hat{\\theta}} \\right)^2}{\\frac{\\partial^2 F}{\\partial \\theta_j^2} \\big|_{\\theta=\\hat{\\theta}}}\n",
        "$$\n",
        "\n",
        "where  \n",
        "\n",
        "- $\\frac{\\partial F}{\\partial \\theta_j}$ = first derivative (score function)  \n",
        "- $\\frac{\\partial^2 F}{\\partial \\theta_j^2}$ = second derivative (information matrix)  \n",
        "- $\\hat{\\theta}$ = estimated parameters under the current model  \n",
        "\n",
        "$MI_j$ approximates the expected drop in the chi-square statistic ($\\Delta \\chi^2$) if the parameter $\\theta_j$ is freed. A large $MI_j$ suggests adding this path/parameter could substantially improve model fit.\n",
        "\n",
        "**Example of modified equations with latent variable $\\eta$:**\n",
        "\n",
        "$$\n",
        "Y = \\beta \\eta + \\gamma X_2 + \\zeta_Y\n",
        "$$\n",
        "\n",
        "$$\n",
        "X_1 = \\lambda_1 \\eta + \\varepsilon_1\n",
        "$$\n",
        "\n",
        "$$\n",
        "X_2 = \\lambda_2 \\eta + \\varepsilon_2\n",
        "$$\n",
        "\n",
        "Here, the new path $\\gamma X_2$ allows $X_2$ to have a direct effect on $Y$, in addition to its effect through the latent variable $\\eta$.\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "Final interpretation of parameters:  \n",
        "\n",
        "- $\\beta$ = 0.6 means that the latent factor $\\eta$ has a moderate-to-strong direct effect on $Y$.  \n",
        "- $\\lambda_1$ = 0.8 means that $X_1$ is a strong indicator of the latent variable $\\eta$.  \n",
        "- $\\lambda_2$ = 0.3 means that $X_2$ is a moderate indicator of the latent variable $\\eta$.  \n",
        "- Indirect effect means that if $X_2$ also has a direct effect on $Y$ ($\\gamma \\neq 0$), then $X_2$ influences $Y$ both directly (via $\\gamma$) and indirectly through $\\eta$ (via $\\lambda_2 \\cdot \\beta$).  "
      ],
      "metadata": {
        "id": "Mbzb05-8PB40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STRUCTURAL CAUSAL MODEL"
      ],
      "metadata": {
        "id": "OMoiIYfBOyyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specification\n",
        "\n",
        "SEM cannot give causal effects but the causal effects can be calculated via SCM and also in SCM, there are no latent variables; causal inference is made solely based on observed variables and their relationships because of it, coefficients in models are calculated via linear or non-linear regression.\n",
        "\n",
        "In SCM, relationships between variables are expressed as structural equations:\n",
        "\n",
        "$$\n",
        "Y = f_Y(X_1, X_2, U_Y)\n",
        "$$  \n",
        "$$\n",
        "X_1 = f_{X_1}(U_{X_1}), \\quad X_2 = f_{X_2}(U_{X_2})\n",
        "$$\n",
        "\n",
        "Where $U$ represents **exogenous (external) variables**.\n",
        "\n",
        "A linear SCM is:\n",
        "\n",
        "$$\n",
        "Y = \\beta_1 X_1 + \\beta_2 X_2 + U_Y\n",
        "$$\n",
        "\n",
        "- Here, $\\beta_1$ & $\\beta_2$ computed via OLS.\n",
        "\n",
        "Graphically, this is represented as a **Directed Acyclic Graph (DAG)** based on SEM **path diagram** and acyclicity is important for both because of that if there is a cycle, it becomes unclear which variable should be computed first, and the model cannot be solved.\n",
        "\n",
        "$$\n",
        "X_1 \\rightarrow Y \\leftarrow X_2\n",
        "$$\n",
        "\n",
        "### Identification\n",
        "\n",
        "In a Structural Causal Model (SCM), identification refers to whether a causal effect can be uniquely estimated from observational data.\n",
        "\n",
        "The causal effect of a variable $X$ on $Y$ is expressed using the **do-operator**:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X=x))\n",
        "$$\n",
        "\n",
        "The do-operator represents an **intervention**: we set $X$ to $x$ externally, breaking any incoming edges into $X$ in the DAG and this distinguishes causal effects from mere correlations.\n",
        "\n",
        "And then, the **backdoor criterion** is a graphical method to determine if $P(Y \\mid do(X))$ can be computed from observational data **theoretically**:\n",
        "\n",
        "A set of variables $Z$ satisfies the backdoor criterion relative to $(X, Y)$ if:\n",
        "\n",
        "1. No variable in $Z$ is a descendant of $X$.\n",
        "2. $Z$ blocks all backdoor paths from $X$ to $Y$.  \n",
        "   - A backdoor path is any path from $X$ to $Y$ that starts with an incoming arrow into $X$.\n",
        "\n",
        "If such a set $Z$ exists, the causal effect is identifiable:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X)) = \\sum_z P(Y \\mid X, Z=z) P(Z=z)\n",
        "$$\n",
        "\n",
        "This formula is called the **backdoor adjustment formula**.\n",
        "\n",
        "Consider a DAG:\n",
        "\n",
        "$$\n",
        "Z \\rightarrow X_1 \\rightarrow Y \\quad \\text{and} \\quad Z \\rightarrow Y\n",
        "$$\n",
        "\n",
        "Here, $Z$ is a confounder creating a backdoor path $X_1 \\leftarrow Z \\rightarrow Y$.  \n",
        "To identify the causal effect of $X_1$ on $Y$, we **condition on $Z$**:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X_1)) = \\sum_z P(Y \\mid X_1, Z=z) P(Z=z)\n",
        "$$\n",
        "\n",
        "This removes the bias introduced by the backdoor path, giving the true causal effect.\n",
        "\n",
        "### Identification\n",
        "\n",
        "In a Structural Causal Model (SCM), identification refers to whether a causal effect can be uniquely estimated from observational data**.\n",
        "\n",
        "The causal effect of a variable $X$ on $Y$ is expressed using the **do-operator**:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X=x))\n",
        "$$\n",
        "\n",
        "The do-operator represents an **intervention**: we set $X$ to $x$ externally, breaking any incoming edges into $X$ in the DAG and this distinguishes causal effects from mere correlations.\n",
        "\n",
        "And then, the **backdoor criterion** is a graphical method to determine if $P(Y \\mid do(X))$ can be computed from observational data **theoretically**:\n",
        "\n",
        "A set of variables $Z$ satisfies the backdoor criterion relative to $(X, Y)$ if:\n",
        "\n",
        "1. No variable in $Z$ is a descendant of $X$.\n",
        "2. $Z$ blocks all backdoor paths from $X$ to $Y$.  \n",
        "   - A backdoor path is any path from $X$ to $Y$ that starts with an incoming arrow into $X$.\n",
        "\n",
        "If such a set $Z$ exists, the causal effect is identifiable:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X)) = \\sum_z P(Y \\mid X, Z=z) P(Z=z)\n",
        "$$\n",
        "\n",
        "This formula is called the **backdoor adjustment formula**.\n",
        "\n",
        "Consider a DAG:\n",
        "\n",
        "$$\n",
        "Z \\rightarrow X_1 \\rightarrow Y \\quad \\text{and} \\quad Z \\rightarrow Y\n",
        "$$\n",
        "\n",
        "Here, $Z$ is a confounder creating a backdoor path $X_1 \\leftarrow Z \\rightarrow Y$.  \n",
        "To identify the causal effect of $X_1$ on $Y$, we **condition on $Z$**:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X_1)) = \\sum_z P(Y \\mid X_1, Z=z) P(Z=z)\n",
        "$$\n",
        "\n",
        "This removes the bias introduced by the backdoor path, giving the true causal effect.\n",
        "\n",
        "Also if some confounders between $X$ and $Y$ are **unobservable** (cannot be included in a backdoor set), the backdoor criterion cannot be applied.  \n",
        "\n",
        "In such cases, if there exists a **mediator $M$** such that $X \\to M \\to Y$, and the following conditions hold:\n",
        "\n",
        "1. $X$ affects $M$.\n",
        "2. All backdoor paths from $X$ to $M$ are blocked by observed variables.\n",
        "3. $M$ intercepts all causal paths from $X$ to $Y$.\n",
        "\n",
        "Then, the **frontdoor criterion** can be used to identify the causal effect via $M$:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X)) = \\sum_m P(M=m \\mid X) \\sum_{x'} P(Y \\mid M=m, X=x') P(X=x')\n",
        "$$\n",
        "\n",
        "This allows identification even in the presence of **unobserved confounding**.\n",
        "\n",
        "### Estimation\n",
        "\n",
        "If a set of variables $Z$ satisfies the backdoor criterion relative to $(X, Y)$, the causal effect of $X$ on $Y$ can be computed as:\n",
        "\n",
        "$$\n",
        "P(Y \\mid do(X=x)) = \\sum_z P(Y \\mid X=x, Z=z) \\, P(Z=z)\n",
        "$$\n",
        "\n",
        "- Here, $P(Y \\mid X, Z)$ is obtained from **observational data**, not theoretical like in identification.  \n",
        "- The summation over $z$ integrates out the confounding effects.  \n",
        "- This gives the **full causal distribution** of $Y$ under the intervention $do(X=x)$.\n",
        "\n",
        "In a linear SCM:\n",
        "\n",
        "$$\n",
        "Y = \\beta_1 X_1 + \\beta_2 X_2 + U_Y\n",
        "$$\n",
        "\n",
        "where $U_Y$ is an exogenous error term independent of $X_1$ and $X_2$.\n",
        "\n",
        "- The expected value of $Y$ under an intervention on $X_1$ depends on whether $X_2$ is independent of $X_1$:\n",
        "\n",
        "If $X_2$ is independent of $X_1$:\n",
        "\n",
        "$$\n",
        "E[Y \\mid do(X_1=x_1)] = \\beta_1 x_1 + \\beta_2 E[X_2]\n",
        "$$\n",
        "\n",
        "- In this case, $\\beta_1$ represents the **causal effect** of $X_1$ on $Y$.\n",
        "\n",
        "If $X_2$ is dependent on $X_1$ (confounding present):\n",
        "\n",
        "$$\n",
        "E[Y \\mid do(X_1=x_1)] = \\beta_1 x_1 + \\beta_2 E[X_2 \\mid do(X_1=x_1)]\n",
        "$$\n",
        "\n",
        "- Here, $\\beta_1$ alone does **not** represent the total causal effect.  \n",
        "- The term $E[X_2 \\mid do(X_1=x_1)]$ accounts for the influence of $X_1$ on $X_2$, i.e., the **confounding pathway**.\n",
        "\n",
        "### Evaluation\n",
        "\n",
        "In SCM, model evaluation is done by comparing the causal inferences with either observational or experimental (RCT) data.\n",
        "\n",
        "Suppose our SCM predicts the causal effect of $X_1$ on $Y$:\n",
        "\n",
        "$$\n",
        "E[Y \\mid do(X_1=1)] - E[Y \\mid do(X_1=0)] = 0.5\n",
        "$$\n",
        "\n",
        "- This means that intervening and setting $X_1$ from 0 to 1 increases the expected outcome by 0.5.  \n",
        "\n",
        "**Observational data** means check if the predicted causal effect is consistent with adjusted estimates while **experimental (RCT) data** means directly intervene on $X_1$ and measure $Y$.  \n",
        "\n",
        "Let $\\hat{E}[Y \\mid do(X_1=1)]$ be the predicted effect, and $E_{\\text{exp}}[Y \\mid X_1=1]$ the experimental outcome:\n",
        "\n",
        "$$\n",
        "\\text{Fit Error} = \\left| \\hat{E}[Y \\mid do(X_1=1)] - E_{\\text{exp}}[Y \\mid X_1=1] \\right|\n",
        "$$\n",
        "\n",
        "- Smaller fit error means better model.  \n",
        "\n",
        "To evaluate the SCM more comprehensively, consider the causal effect across the **entire range of $X_1$**. Metrics such as **Mean Squared Error (MSE)**, **Bias**, and **Variance** can be computed.\n",
        "\n",
        "**Mean Squared Error (MSE):**\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left(\\hat{E}[Y \\mid do(X_1=x_i)] - E_{\\text{exp}}[Y \\mid X_1=x_i] \\right)^2\n",
        "$$\n",
        "\n",
        "- Smaller MSE indicates better overall fit across the intervention range.\n",
        "\n",
        "**Bias:**\n",
        "\n",
        "$$\n",
        "\\text{Bias} = \\frac{1}{n} \\sum_{i=1}^{n} \\left(\\hat{E}[Y \\mid do(X_1=x_i)] - E[Y \\mid do(X_1=x_i)] \\right)\n",
        "$$\n",
        "\n",
        "- Positive bias means overestimation; negative bias means underestimation & zero bias indicates unbiased causal effect estimation on average.\n",
        "\n",
        "**Variance:**\n",
        "\n",
        "$$\n",
        "\\text{Variance} = \\frac{1}{n} \\sum_{i=1}^{n} \\left(\\hat{E}[Y \\mid do(X_1=x_i)] - \\overline{\\hat{E}[Y \\mid do(X_1)]} \\right)^2\n",
        "$$\n",
        "\n",
        "- High variance indicates predictions are sensitive to changes in $X_1$, even if unbiased.\n",
        "\n",
        "- These metrics provide a more complete assessment of model performance across all possible interventions on $X_1$, rather than just a single value.\n",
        "\n",
        "### Modification\n",
        "\n",
        "If confounders are missing or directions are wrong, the DAG must be revised via theory or causal discovery algorithms:\n",
        "\n",
        "- **PC Algorithm**: Uses conditional independence tests to infer DAG edges and directions.  \n",
        "- **GES (Greedy Equivalence Search)**: Score-based search over DAG structures to find the best-fitting model.  \n",
        "- **LiNGAM (Linear Non-Gaussian Acyclic Model)**: Assumes linear relations with non-Gaussian errors to identify causal directions.\n",
        "\n",
        "Previous:\n",
        "\n",
        "$$\n",
        "P(X_1, X_2, Y) = P(X_1) P(X_2) P(Y \\mid X_1, X_2)\n",
        "$$\n",
        "\n",
        "means\n",
        "\n",
        "$$\n",
        "X_1 \\;\\; \\longrightarrow \\;\\; Y \\;\\; \\longleftarrow \\;\\; X_2\n",
        "$$\n",
        "\n",
        "Updated:\n",
        "\n",
        "$$\n",
        "P(X_1, X_2, Y) = P(X_2) P(X_1 \\mid X_2) P(Y \\mid X_1, X_2)\n",
        "$$\n",
        "\n",
        "means\n",
        "\n",
        "$$\n",
        "X_2 \\;\\; \\longrightarrow \\;\\; X_1 \\;\\; \\longrightarrow \\;\\; Y, \\;\\; X_2 \\;\\; \\longrightarrow \\;\\; Y\n",
        "$$\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "SCM interprets **causal effects** rather than regression coefficients:\n",
        "\n",
        "$$\n",
        "E[Y \\mid do(X_1=1)] - E[Y \\mid do(X_1=0)] = 0.5\n",
        "$$\n",
        "\n",
        "It means that a one-unit increase in $X_1$ **causally increases** $Y$ by 0.5 on average.\n",
        "\n",
        "### Counterfactualization\n",
        "\n",
        "SCM allows us to reason about **counterfactuals**, which answer questions like:\n",
        "\n",
        "*\"What would $Y$ have been if $X_1$ had taken a different value, given what we actually observed?\"*\n",
        "\n",
        "A counterfactual is denoted as:\n",
        "\n",
        "$$\n",
        "Y_{X_1=x'} \\;\\;\\text{given that actually}\\;\\; X_1=x, X_2=x_2, Y=y\n",
        "$$\n",
        "\n",
        "Counterfactual computation in SCM typically involves three steps:\n",
        "\n",
        "**Abduction:** Estimate the exogenous variables $U$ based on the observed data:\n",
        "\n",
        "$$\n",
        "U_Y = Y - (\\beta_1 X_1 + \\beta_2 X_2), \\quad\n",
        "U_{X_2} = f_{X_2}^{-1}(X_2)\n",
        "$$\n",
        "\n",
        "**Action:** Intervene to set $X_1$ to the counterfactual value $x'$ using the do-operator:\n",
        "\n",
        "$$\n",
        "do(X_1 = x')\n",
        "$$\n",
        "\n",
        "**Prediction:** Compute the counterfactual outcome using the structural equations and the exogenous variables, adjusting all other relevant variables:\n",
        "\n",
        "$$\n",
        "X_2^{cf} = f_{X_2}(U_{X_2}) \\quad \\Rightarrow \\quad\n",
        "Y_{X_1=x'} = \\beta_1 x' + \\beta_2 X_2^{cf} + U_Y\n",
        "$$\n",
        "\n",
        "- Here, $X_2^{cf}$ is the counterfactual value of $X_2$ computed using its exogenous variable $U_{X_2}$ and this ensures that all dependent variables are correctly updated, rather than keeping them fixed at observed values.\n",
        "\n",
        "As is seen, SCM without counterfactuals gives **average causal effects**, while SCM with counterfactuals gives **individual causal effects** that properly account for all dependencies."
      ],
      "metadata": {
        "id": "tvqxzg1DPCbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ARCHITECTURES IN PYTHON"
      ],
      "metadata": {
        "id": "IBlcx6mXOo2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STRUCTURAL EQUATION MODEL IN PYTHON"
      ],
      "metadata": {
        "id": "zQsocRDjO1z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOON"
      ],
      "metadata": {
        "id": "3NBxM2JqO7Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STRUCTURAL CAUSAL MODEL IN PYTHON"
      ],
      "metadata": {
        "id": "Mi1Rw2q2O4LL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIjylpiAOFQc"
      },
      "outputs": [],
      "source": [
        "# SOON"
      ]
    }
  ]
}