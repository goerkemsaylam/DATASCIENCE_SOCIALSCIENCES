{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NeGwEa3iZ9zo",
        "tFJISeVgIGmV",
        "MprNMMBeIJR4",
        "gIxoG4WSaouY",
        "MnF4qmhp_ikU",
        "l0StTlp0_nGd",
        "hS51RalxJS_O",
        "TiXd7RIGNy8v",
        "CQjaBQy_FMSf",
        "wDcm2_aNFmBt",
        "NT9rxouVF49t",
        "ykcHg7p5GMB2",
        "VXRhXazpGZPG",
        "vH8WDrfYGmAh",
        "nWncR0H0GxPZ",
        "i2X4J2EWG-Ib",
        "3kbchtEdHG_u",
        "atknrzK2HPWH",
        "vwQS5YcKHYSV",
        "mgy0rDnEHinX",
        "tJaOSKaGHqZu",
        "v9Ja6EZuHuv2",
        "tNVlYajZH3cd",
        "pJNKQJ1CH6VG",
        "YogBXVplHxpo",
        "PAtGC3R3H0wP",
        "8ZmaMchOH-Ld",
        "hqINOwPZRNIN",
        "tvFChot7WnG5",
        "hydyVWRMYttP",
        "utRlYNxyIBMa",
        "zxGW6bU6IHWs",
        "N7ZCgw_VN7E7",
        "-OzusB5CImtd",
        "tyY4SKfsIuW8",
        "axZ9U0_tI4pd",
        "gA5U4im7I_ai",
        "58T_GYiKJKgQ",
        "o8T5kCsiJMKl",
        "sSjb354HJbAF",
        "uE86aluRa4CS",
        "GTl9jFjbGGs6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SAMPLE PRE-PROCESSING"
      ],
      "metadata": {
        "id": "NeGwEa3iZ9zo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAMPLE SIZE"
      ],
      "metadata": {
        "id": "tFJISeVgIGmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "General sample size formula is:\n",
        "\n",
        "$$\n",
        "n \\propto \\frac{(Z_{1-\\alpha/2} + Z_{1-\\beta})^2}{\\Delta^2}\n",
        "$$\n",
        "\n",
        "**Where:**  \n",
        "- $n$: required sample size  \n",
        "- $Z_{1-\\alpha/2}$: critical value corresponding to the chosen significance level  \n",
        "- $Z_{1-\\beta}$: critical value corresponding to the desired power  \n",
        "- $\\Delta$: the magnitude of difference or relationship effect in the study\n",
        "\n",
        "To calculate sample size, significance level as 0.05/0.01 & power as 0.8/0.9 are known and also effect size must be defined by the researcher based on the study.\n",
        "\n",
        "This general sample size formula also must be specialized to hypothesis test that applied because each hypothesis test has own sample size formula.\n",
        "\n",
        "t-Test & Wilcoxons:\n",
        "\n",
        "  - Independent t-Test & Wilcoxon Rank Sum:  \n",
        "  $$ n = 2 \\left( \\frac{(Z_{\\alpha} + Z_{\\beta}) \\sigma}{d} \\right)^2\n",
        "  \\text{where } \\sigma = \\text{population standard deviation, } d = \\text{effect size} $$\n",
        "  - Paired t-Test & Wilcoxon Signed Rank:  \n",
        "  $$ n = \\left( \\frac{(Z_{\\alpha} + Z_{\\beta}) \\sigma_d}{d} \\right)^2 \\text{where } \\sigma_d = \\text{standard deviation of differences, } d = \\text{effect size}$$\n",
        "\n",
        "One-Way ANOVA, One-Way RM ANOVA, Kruskal-Wallis & Friedman:  \n",
        "\n",
        "$$ n = \\frac{(Z_{\\alpha} + Z_{\\beta})^2}{f^2} \\text{where } f = \\text{Cohen's f (effect size)}$$\n",
        "\n",
        "Two-Way ANOVA, Two-Way RM ANOVA, SRH, Aligned Rank Transform, Chi-Square Homogeneity & Chi-Square Independence:  \n",
        "\n",
        "$$ n = \\frac{(Z_{\\alpha} + Z_{\\beta})^2}{f^2} \\quad \\text{where } f = \\text{Cohen's f (or Cohen's w for chi-Square)} $$\n",
        "\n",
        "One-Way MANOVA, Two-Way MANOVA, One-Way RM MANOVA, Two-Way RM MANOVA, PERMANOVA One-Way, PERMANOVA Two-Way, Wilks Lambda One-Way & Wilks Lambda Two-Way:\n",
        "\n",
        "$$ N = \\frac{(Z_{\\alpha} + Z_{\\beta})^2 \\cdot (u+v+1)}{u \\cdot f^2} \\text{where } u = \\text{number of dependent variables, } v = \\text{degrees of freedom denominator, } f = \\text{effect size} $$\n",
        "\n",
        "Pearson & Spearman Correlation (Fisher-z):\n",
        "\n",
        "$$ n = \\frac{(Z_{\\alpha} + Z_{\\beta})^2}{\\left( \\frac{1}{2} \\ln \\frac{1+r}{1-r} \\right)^2} \\text{where } r = \\text{expected correlation coefficient} $$"
      ],
      "metadata": {
        "id": "M5OnUoTZaddg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAMPLE DISTRIBUTION"
      ],
      "metadata": {
        "id": "MprNMMBeIJR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shapiro-Wilk Test for Normality\n",
        "\n",
        "To detect whether a continuous numerical variable follows a normal distribution for parametricity via Shapiro-Wilk stat (W).\n",
        "\n",
        "Shapiro-Wilk stat (W) is:\n",
        "\n",
        "$$\n",
        "W = \\frac{\\left( \\sum_{i=1}^{n} a_i x_{(i)} \\right)^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $x_{(i)}$: Ordered sample values (from smallest to largest)  \n",
        "- $x_i$: Original sample values  \n",
        "- $\\bar{x}$: Sample mean  \n",
        "- $a_i$: Constants derived from the expected values of order statistics of a standard normal distribution  \n",
        "- $n$: Sample size  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{W value} & \\textbf{Normality} \\\\\n",
        "\\hline\n",
        "W \\approx 1 & \\text{Data is approximately normal} \\\\\n",
        "W < 0.95 & \\text{Slight deviation from normality} \\\\\n",
        "W < 0.90 & \\text{Moderate deviation from normality} \\\\\n",
        "W < 0.80 & \\text{Strong deviation from normality} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is W-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population data of a continuous numerical variable **is not** anormally distributed.   \n",
        "- **Alternative hypothesis (H1):** The population data of a continuous numerical variable **is** anormally distributed.  \n",
        "\n",
        "To reject H0 (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. W to P-Value via Sample Size**\n",
        "\n",
        "The Shapiro-Wilk test directly calculates p-value for W via sample size tables to use ready and the p-value is:  \n",
        "\n",
        "- **Two-Tailed:**  \n",
        "\n",
        "$$\n",
        "p = P(\\text{W observed} \\le W)\n",
        "$$\n",
        "\n",
        "**3. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "Here,  α  is theoretically assumed as 0.05-0.01 generally."
      ],
      "metadata": {
        "id": "Y4yvdKItINXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAMPLE PRE-PROCESSING IN PYTHON"
      ],
      "metadata": {
        "id": "gIxoG4WSaouY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAMPLE SIZE IN PYTHON"
      ],
      "metadata": {
        "id": "MnF4qmhp_ikU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOON"
      ],
      "metadata": {
        "id": "UHhqJrADMwmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAMPLE DISTRIBUTION IN PYTHON"
      ],
      "metadata": {
        "id": "l0StTlp0_nGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOON"
      ],
      "metadata": {
        "id": "UJbRyHCFNLcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFIRMATORY DATA ANALYSIS"
      ],
      "metadata": {
        "id": "hS51RalxJS_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CDA means analysis via **HYPOTHESIS TESTS**.\n",
        "\n",
        "And the analysis via hypothesis tests can be categorized in 2 types hierarchically as **inter-group** & **inter-variable**."
      ],
      "metadata": {
        "id": "7-EaPyafJafo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTER-GROUP ANALYSIS"
      ],
      "metadata": {
        "id": "TiXd7RIGNy8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametric Tests For Continuous Numerical Inter-Group"
      ],
      "metadata": {
        "id": "CQjaBQy_FMSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Independent t-Test"
      ],
      "metadata": {
        "id": "wDcm2_aNFmBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a difference between two different continuous numerical groups via t-stat.\n",
        "\n",
        "t-stat is:  \n",
        "\n",
        "$$\n",
        "t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
        "$$\n",
        "\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\bar{x}_1, \\bar{x}_2$: Sample means of group 1 and group 2\n",
        "- $s_1^2, s_2^2$: Sample variances of group 1 and group 2\n",
        "- $n_1, n_2$: Sample sizes of group 1 and group 2\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$|t|$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "|t| < 1 & \\text{No difference} \\\\\n",
        "1 \\le |t| < 2 & \\text{Weak difference} \\\\\n",
        "2 \\le |t| < 3 & \\text{Moderate difference} \\\\\n",
        "3 \\le |t| < 5 & \\text{Strong difference} \\\\\n",
        "|t| \\ge 5 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is t-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population difference between two different groups **is not** significantly different.\n",
        "\n",
        "**Alternative hypothesis (H1):** The population difference between two different groups **is** significantly different.\n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, every parametric distribution has a **degrees of freedom (df)** value, and for the t-stat, that is, the t-distribution, **df = n1 + n2 − 2**.\n",
        "\n",
        "Under H0, the t-stat follows t-distribution and the probability density function (PDF) is:\n",
        "$$\n",
        "f(t) = \\frac{\\Gamma\\left(\\frac{df+1}{2}\\right)}{\\sqrt{df \\pi}\\, \\Gamma\\left(\\frac{df}{2}\\right)} \\left(1 + \\frac{t^2}{df}\\right)^{-\\frac{df+1}{2}}\n",
        "$$\n",
        "\n",
        "To integrate PDF to t as the cumulative distribution function (CDF) is:\n",
        "$$\n",
        "F(t) = \\int_{-\\infty}^{t} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "F(t) = P(T \\le t)\n",
        "$$\n",
        "\n",
        "It means the probability of values less than or equal to t.\n",
        "\n",
        "- **One-Tailed:**  \n",
        "  - Used when H0: parameter ≤ value, H1: parameter > value as **upper-tailed test** and the “extreme values” of interest are greater than t. Therefore, the p-value is:\n",
        "  $$\n",
        "  p = 1 - F(t)\n",
        "  $$  \n",
        "  - Used when H0: parameter ≥ value, H1: parameter < value as **lower-tailed test** and therefore, the p-value is directly:\n",
        "  $$\n",
        "  p = F(t)\n",
        "  $$\n",
        "\n",
        "- **Two-Tailed:**  \n",
        "\n",
        "  - Used when H0: parameter = value, H1: parameter ≠ value (i.e., \"different\") and to cover extreme values in both the upper and lower tails by using absolute value of t and formula multiplication by 2. Therefore, the p-value is:\n",
        "  $$\n",
        "  p = 2 \\cdot (1 - F(|t|))\n",
        "  $$  \n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "Here, $\\alpha$ is theoretically assumed as 0.05-0.01 generally."
      ],
      "metadata": {
        "id": "Bd-jnRHzFT5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Paired t-Test"
      ],
      "metadata": {
        "id": "NT9rxouVF49t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a difference between two related continuous numerical groups via t-stat.\n",
        "\n",
        "t-stat is:  \n",
        "\n",
        "$$\n",
        "t = \\frac{\\bar{d}}{s_d / \\sqrt{n}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\bar{d}$: Mean of the differences between paired observations  \n",
        "- $s_d$: Standard deviation of the differences  \n",
        "- $n$: Number of pairs  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$|t|$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "|t| < 1 & \\text{No difference} \\\\\n",
        "1 \\le |t| < 2 & \\text{Weak difference} \\\\\n",
        "2 \\le |t| < 3 & \\text{Moderate difference} \\\\\n",
        "3 \\le |t| < 5 & \\text{Strong difference} \\\\\n",
        "|t| \\ge 5 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is t-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population difference between two related groups **is not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population difference between two related groups **is** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, every parametric distribution has a **degrees of freedom (df)** value, and for the paired t-stat, that is, the t-distribution,  \n",
        "\n",
        "$$\n",
        "df = n - 1\n",
        "$$  \n",
        "\n",
        "Under H0, the t-stat follows t-distribution and the probability density function (PDF) is:  \n",
        "\n",
        "$$\n",
        "f(t) = \\frac{\\Gamma\\left(\\frac{df+1}{2}\\right)}{\\sqrt{df \\pi}\\, \\Gamma\\left(\\frac{df}{2}\\right)} \\left(1 + \\frac{t^2}{df}\\right)^{-\\frac{df+1}{2}}\n",
        "$$\n",
        "\n",
        "To integrate PDF to t as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(t) = \\int_{-\\infty}^{t} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "F(t) = P(T \\le t)\n",
        "$$\n",
        "\n",
        "It means the probability of values less than or equal to t.  \n",
        "\n",
        "- **One-Tailed:**  \n",
        "  - H0: parameter ≤ value, H1: parameter > value (**upper-tailed test**):  \n",
        "  $$\n",
        "  p = 1 - F(t)\n",
        "  $$  \n",
        "  - H0: parameter ≥ value, H1: parameter < value (**lower-tailed test**):  \n",
        "  $$\n",
        "  p = F(t)\n",
        "  $$  \n",
        "\n",
        "- **Two-Tailed:**  \n",
        "  - H0: parameter = value, H1: parameter ≠ value:  \n",
        "  $$\n",
        "  p = 2 \\cdot (1 - F(|t|))\n",
        "  $$  \n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is theoretically assumed as 0.05–0.01 generally."
      ],
      "metadata": {
        "id": "xAlECmS0F7bF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Way ANOVA Test"
      ],
      "metadata": {
        "id": "ykcHg7p5GMB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different continuous numerical groups on an independent variable via F-stat.\n",
        "\n",
        "F-stat is:  \n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{between}}}{\\text{MS}_{\\text{within}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{between}}$: Mean square between groups  \n",
        "- $\\text{MS}_{\\text{within}}$: Mean square within groups  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population difference between two or more different groups on an independent variable **is not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population difference between two or more different groups on an independent variable **is** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, F-distribution has **degrees of freedom (df1, df2)** values:  \n",
        "\n",
        "- $df_1 = k - 1$ (between groups)  \n",
        "- $df_2 = N - k$ (within groups)  \n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k$: Independent groups\n",
        "- $N$: Sample size total\n",
        "\n",
        "Under H0, the F-stat follows F-distribution and the probability density function (PDF) is:  \n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "As is seen, to normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because of that F-stat is based on squared differences, so it cannot take negative values. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference and the lower-tailed test logic is not meaningful for F-test.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "71sybrTTGODs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Two-Way ANOVA Test"
      ],
      "metadata": {
        "id": "VXRhXazpGZPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different continuous numerical groups on two different independent variables via F-stat.\n",
        "\n",
        "F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{effect}}}{\\text{MS}_{\\text{within}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{effect}}$: Mean square for the effect (Factor A, Factor B, or A×B interaction)  \n",
        "- $\\text{MS}_{\\text{within}}$: Mean square within groups (residual/error)  \n",
        "\n",
        "And its interpretation is similar to One-Way ANOVA:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population difference between two or more different groups on two independent variables **is not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population difference between two or more different groups on two independent variables **is** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, F-distribution has **degrees of freedom (df1, df2)** values:  \n",
        "\n",
        "- $df_1 = k_{\\text{effect}} - 1$ (between groups for that effect)  \n",
        "- $df_2 = N - k_{\\text{total}}$ (within groups / residual)\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k_{\\text{effect}}$: Number of levels in the factor or interaction  \n",
        "- $k_{\\text{total}}$: Total number of groups  \n",
        "- $N$: Total sample size\n",
        "\n",
        "Under H0, the F-stat follows F-distribution and the probability density function (PDF) is:  \n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "To normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because the F-stat is based on squared differences, so it cannot take negative values. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference; lower-tailed test is not meaningful.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "FjOKXrf3GbB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Way Repeated Measures ANOVA Test"
      ],
      "metadata": {
        "id": "vH8WDrfYGmAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more repeated continuous numerical measurements on the same group on an independent variable via F-stat.\n",
        "\n",
        "F-stat is:  \n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{between}}}{\\text{MS}_{\\text{residual}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{between}}$: Mean square between repeated measures\n",
        "- $\\text{MS}_{\\text{residual}}$: Mean square of residuals\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population difference between two or more repeated measurements on the same group on an independent variable **is not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population difference between two or more repeated measurements on the same group on an independent variable **is** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, repeated measures F-distribution has **degrees of freedom (df1, df2)** values:\n",
        "\n",
        "- $df_1 = k - 1$  \n",
        "- $df_2 = (n - 1)(k - 1)$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k$: Number of repeated measurements  \n",
        "- $n$: Number of subjects\n",
        "\n",
        "Under H0, the F-stat follows F-distribution and the probability density function (PDF) is:  \n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "To normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because the F-stat is based on squared differences, so it cannot take negative values. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference; lower-tailed test is not meaningful.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "JPFdxeNoGnod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Two-Way Repeated Measures ANOVA Test"
      ],
      "metadata": {
        "id": "nWncR0H0GxPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more repeated continuous numerical measurements on the same group on two independent variables via F-stat.\n",
        "\n",
        "F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{effect}}}{\\text{MS}_{\\text{residual}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{effect}}$: Mean square for the effect\n",
        "- $\\text{MS}_{\\text{residual}}$: Mean square of residuals\n",
        "\n",
        "And its interpretation is similar to One-Way Repeated Measures ANOVA:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population difference between two or more repeated measurements on the same group on two independent variables **is not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population difference between two or more repeated measurements on the same group on two independent variables **is** significantly different.\n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, repeated measures F-distribution has **degrees of freedom (df1, df2)** values:\n",
        "\n",
        "- $df_1 = k_{\\text{effect}} - 1$\n",
        "- $df_2 = (n - 1)(k_{\\text{effect}} - 1)$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k_{\\text{effect}}$: Number of levels in the factor or interaction  \n",
        "- $n$: Number of subjects\n",
        "\n",
        "Under H0, the F-stat follows F-distribution and the probability density function (PDF) is:  \n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "To normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because the F-stat is based on squared differences, so it cannot take negative values. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference; lower-tailed test is not meaningful.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "PwJRBNhMGyp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Way MANOVA Test"
      ],
      "metadata": {
        "id": "i2X4J2EWG-Ib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different continuous numerical groups on an independent variable & multiple dependent variables via multivariate F-stat.\n",
        "\n",
        "Multivariate F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{between}}}{\\text{MS}_{\\text{within}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{between}}$: Mean square between groups\n",
        "- $\\text{MS}_{\\text{within}}$: Mean square within groups\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is multivariate F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population differences between two or more different continuous numerical groups on an independent variable & multiple dependent variables **are not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population differences between two or more different continuous numerical groups on an independent variable & multiple dependent variables **are** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, multivariate F-distribution has **degrees of freedom (df1, df2)** values:\n",
        "\n",
        "- $df_1 = p \\cdot (k - 1)$   \n",
        "- $df_2 = N - k - p + 1$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k$: Number of independent groups  \n",
        "- $p$: Number of dependent variables  \n",
        "- $N$: Total sample size\n",
        "\n",
        "Under H0, the F-stat follows an approximate F-distribution and the probability density function (PDF) is:\n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "To normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because F-stat is based on squared differences; negative values cannot occur. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference; lower-tailed test is not meaningful.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "WZyQ5RwcG_cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Two-Way MANOVA Test"
      ],
      "metadata": {
        "id": "3kbchtEdHG_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different continuous numerical groups on two independent variables & multiple dependent variables via multivariate F-stat.\n",
        "\n",
        "Multivariate F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{effect}}}{\\text{MS}_{\\text{within}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{effect}}$: Mean square for the effect\n",
        "- $\\text{MS}_{\\text{within}}$: Mean square within groups\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is multivariate F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population differences between two or more different continuous numerical groups on two independent variables & multiple dependent variables **are not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population differences between two or more different continuous numerical groups on two independent variables & multiple dependent variables **are** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, multivariate F-distribution has **degrees of freedom (df1, df2)** values:\n",
        "\n",
        "- $df_1 = p \\cdot (k_{\\text{effect}} - 1)$\n",
        "- $df_2 = N - k_{\\text{effect}} - p + 1$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k_{\\text{effect}}$: Number of levels in the factor or interaction  \n",
        "- $p$: Number of dependent variables  \n",
        "- $N$: Total sample size\n",
        "\n",
        "Under H0, the F-stat follows an approximate F-distribution and the probability density function (PDF) is:\n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "To normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because F-stat is based on squared differences; negative values cannot occur. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference; lower-tailed test is not meaningful.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "3I1wKimKHIgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Way Repeated Measures MANOVA Test"
      ],
      "metadata": {
        "id": "atknrzK2HPWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more repeated continuous measurements on the same group on an independent variable & multiple dependent variables via multivariate F-stat.\n",
        "\n",
        "Multivariate F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{between}}}{\\text{MS}_{\\text{residual}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{between}}$: Mean square between repeated measures\n",
        "- $\\text{MS}_{\\text{residual}}$: Mean square of residuals  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is multivariate F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population differences between repeated measurements on the same group on an independent variable & multiple dependent variables **are not** significantly different.  \n",
        "\n",
        "**Alternative hypothesis (H1):** The population differences between repeated measurements on the same group on an independent variable & multiple dependent variables **are** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, repeated measures multivariate F-distribution has **degrees of freedom (df1, df2)** values:\n",
        "\n",
        "- $df_1 = p \\cdot (k - 1)$  \n",
        "- $df_2 = (n - 1) \\cdot (k - 1)$  \n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k$: Number of repeated measurements  \n",
        "- $n$: Number of subjects  \n",
        "- $p$: Number of dependent variables  \n",
        "\n",
        "Under H0, the F-stat follows an approximate F-distribution and the probability density function (PDF) is:\n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "To normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because F-stat is based on squared differences; negative values cannot occur. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference; lower-tailed test is not meaningful.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "TgibCl_6HQqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Two-Way Repeated Measures MANOVA Test"
      ],
      "metadata": {
        "id": "vwQS5YcKHYSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between repeated continuous measurements on the same group on two independent variables & multiple dependent variables via multivariate F-stat.\n",
        "\n",
        "Multivariate F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{MS}_{\\text{effect}}}{\\text{MS}_{\\text{residual}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{MS}_{\\text{effect}}$: Mean square for a main effect\n",
        "- $\\text{MS}_{\\text{residual}}$: Mean square of residuals\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference} \\\\\n",
        "1 < F < 3 & \\text{Weak difference} \\\\\n",
        "3 \\le F < 5 & \\text{Moderate difference} \\\\\n",
        "5 \\le F < 10 & \\text{Strong difference} \\\\\n",
        "F \\ge 10 & \\text{Very strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is multivariate F-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between repeated continuous measurements on the same group on two independent variables & multiple dependent variables **are not** significantly different.  \n",
        "- **Alternative hypothesis (H1):** The population differences between repeated continuous measurements on the same group on two independent variables & multiple dependent variables **are** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Like t-distribution, repeated measures multivariate F-distribution has **degrees of freedom (df1, df2)** values with **two independent variables (A, B)**:\n",
        "\n",
        "- **For Independent Variable A:** $df_1 = p \\cdot (k_A - 1)$, $df_2 = (n - 1) \\cdot (k_A - 1)$  \n",
        "- **For Independent Variable B:** $df_1 = p \\cdot (k_B - 1)$, $df_2 = (n - 1) \\cdot (k_B - 1)$  \n",
        "- **For Interaction A×B:** $df_1 = p \\cdot (k_A - 1)(k_B - 1)$, $df_2 = (n - 1) \\cdot (k_A - 1)(k_B - 1)$  \n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $k_A$, $k_B$: Number of levels for independent variables A and B  \n",
        "- $n$: Number of subjects  \n",
        "- $p$: Number of dependent variables  \n",
        "\n",
        "Under H0, the F-stat follows an approximate F-distribution and the probability density function (PDF) is:\n",
        "\n",
        "$$\n",
        "f(F) = \\frac{\\sqrt{\\frac{(df_1 F)^{df_1} df_2^{df_2}}{(df_1 F + df_2)^{df_1 + df_2}}}}{F B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right)}\n",
        "$$\n",
        "\n",
        "To normalize PDF by Beta function:\n",
        "\n",
        "$$\n",
        "B\\left(\\frac{df_1}{2}, \\frac{df_2}{2}\\right) = \\int_0^1 t^{\\frac{df_1}{2}-1} (1-t)^{\\frac{df_2}{2}-1} \\, dt\n",
        "$$\n",
        "\n",
        "To integrate PDF to F as the cumulative distribution function (CDF) is:  \n",
        "\n",
        "$$\n",
        "F(F) = \\int_{0}^{F} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**3. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p = P(F_{\\text{obs}} \\le F) = 1 - F(F_{\\text{obs}})\n",
        "$$\n",
        "\n",
        "As is seen, the F-distribution is one-sided because F-stat is based on squared differences; negative values cannot occur. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a difference; lower-tailed test is not meaningful.\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "xGxM3Z2-HZik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Parametric Tests For Numerical & Ordinal Categorical Inter-Group"
      ],
      "metadata": {
        "id": "mgy0rDnEHinX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Wilcoxon Rank-Sum Test For Independent t-Test"
      ],
      "metadata": {
        "id": "tJaOSKaGHqZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a difference between two different numerical & ordinal groups via  rank-sum (U) stat.\n",
        "\n",
        "Wilcoxon rank-sum stat (U) is:\n",
        "\n",
        "$$\n",
        "U = n_1 n_2 + \\frac{n_1 (n_1 + 1)}{2} - R_1\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $U$ : Wilcoxon rank-sum statistic  \n",
        "- $n_1, n_2$ : Sample sizes of group 1 and group 2  \n",
        "- $R_1$ : Sum of ranks for group 1  \n",
        "- (Similarly, $U$ can be computed from $R_2$ for group 2, and $U_1 + U_2 = n_1 n_2$)\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "$$\n",
        "0 \\leq U \\leq n_1 \\cdot n_2\n",
        "$$\n",
        "\n",
        "- The smallest $U$ (≈ 0) → one group completely dominates the other (large difference).  \n",
        "\n",
        "- The largest $U$ (≈ $n_1 \\cdot n_2$) → one group completely dominates the other (large difference).  \n",
        "\n",
        "- The middle value (≈ $n_1 \\cdot n_2 / 2$) → the groups are similar (no difference).  \n",
        "\n",
        "It is Wilcoxon U-stat of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The two population difference between two different numerical & ordinal groups **is not** significantly different.  \n",
        "- **Alternative hypothesis (H1):** The two population difference between two different numerical & ordinal groups **is** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Wilcoxon U Statistic via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate Wilcoxon U stat to get empirical probability distributions, not theoretical distributions like t-distribution.  \n",
        "\n",
        "Randomly shuffle the group labels between the two samples. This simulates the null hypothesis H0, where no group difference exists.  \n",
        "\n",
        "For each permutation $j$, compute a new Wilcoxon U stat:  \n",
        "\n",
        "$$\n",
        "U_{\\text{perm}}^{(j)} = \\text{WilcoxonRankSum}(X^{(j)}_1, X^{(j)}_2)\n",
        "$$\n",
        "\n",
        "Repeat this process N times (e.g., 10,000) to generate the null distribution of U under H0.  \n",
        "\n",
        "**3. Wilcoxon U Stat to P-Value**\n",
        "\n",
        "- **One-Tailed:**  \n",
        "  - Upper-tailed (H1: Group1 > Group2):  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } U_{\\text{perm}}^{(j)} \\ge U_{\\text{obs}}}{N}\n",
        "$$  \n",
        "\n",
        "  - Lower-tailed (H1: Group1 < Group2):  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } U_{\\text{perm}}^{(j)} \\le U_{\\text{obs}}}{N}\n",
        "$$  \n",
        "\n",
        "- **Two-Tailed:**  \n",
        "  - Used when H0: groups equal, H1: groups different. Both extremes are considered:  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } |U_{\\text{perm}}^{(j)} - \\mu_U| \\ge |U_{\\text{obs}} - \\mu_U|}{N}\n",
        "$$  \n",
        "\n",
        "Here, $\\mu_U = \\frac{n_1 n_2}{2}$ is the expected mean of $U$ under H0.  \n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01.  "
      ],
      "metadata": {
        "id": "i6yMtiYsKFGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Wilcoxon Signed-Rank Test For Paired t-Test"
      ],
      "metadata": {
        "id": "v9Ja6EZuHuv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a difference between two related numerical & ordinal groups via signed-rank (W) stat.  \n",
        "\n",
        "Wilcoxon signed-rank statistic (W) is:  \n",
        "\n",
        "$$\n",
        "W = \\sum_{i=1}^n \\operatorname{sgn}(d_i)\\,R_i\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $W$ : Wilcoxon signed-rank statistic  \n",
        "- $n$ : Number of paired observations (excluding $d_i = 0$ ties)  \n",
        "- $d_i = x_i - y_i$ : Difference between the paired values  \n",
        "- $R_i$ : Rank of $|d_i|$ (absolute differences)  \n",
        "- $\\operatorname{sgn}(d_i)$ : Sign function (+1 if $d_i > 0$, –1 if $d_i < 0$)   \n",
        "\n",
        "And its interpretation is:  \n",
        "\n",
        "- $W \\approx 0$ → the two paired samples are similar (no difference).  \n",
        "\n",
        "- Large positive $W$ (close to $+\\tfrac{n(n+1)}{2}$) → the first sample tends to be larger than the second (large difference).  \n",
        "\n",
        "- Large negative $W$ (close to $-\\tfrac{n(n+1)}{2}$) → the second sample tends to be larger than the first (large difference).  \n",
        "\n",
        "It is Wilcoxon W-stat of sample and to inference for population, hypothesis test must be used.  \n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population difference between two related numerical & ordinal groups **is not** significantly different.  \n",
        "- **Alternative hypothesis (H1):** The population difference between two related numerical & ordinal groups **is** significantly different.\n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Wilcoxon W Stat via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate Wilcoxon W stat to get empirical probability distributions, not theoretical distributions like t-distribution.  \n",
        "\n",
        "Randomly flip the signs of $d_i$ (differences) with 50% probability. This simulates the null hypothesis H0, where no systematic difference exists.  \n",
        "\n",
        "For each permutation $j$, compute a new Wilcoxon W stat:  \n",
        "\n",
        "$$\n",
        "W_{\\text{perm}}^{(j)} = \\text{WilcoxonSignedRank}(d_1^{(j)}, d_2^{(j)}, \\dots, d_n^{(j)})\n",
        "$$  \n",
        "\n",
        "Repeat this process N times (e.g., 10,000) to generate the null distribution of W under H0.  \n",
        "\n",
        "**3. Wilcoxon W Stat to P-Value**\n",
        "\n",
        "- **One-Tailed:**  \n",
        "  - Upper-tailed (H1: group difference > 0):  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } W_{\\text{perm}}^{(j)} \\ge W_{\\text{obs}}}{N}\n",
        "$$  \n",
        "\n",
        "  - Lower-tailed (H1: group difference < 0):  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } W_{\\text{perm}}^{(j)} \\le W_{\\text{obs}}}{N}\n",
        "$$  \n",
        "\n",
        "- **Two-Tailed:**  \n",
        "  - Used when H0: differences = 0, H1: differences ≠ 0. Both extremes are considered:  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } |W_{\\text{perm}}^{(j)}| \\ge |W_{\\text{obs}}|}{N}\n",
        "$$  \n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01.  "
      ],
      "metadata": {
        "id": "8Dut8EsfNQNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kruskal–Wallis H Test For One-Way ANOVA Test"
      ],
      "metadata": {
        "id": "tNVlYajZH3cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different numerical & ordinal categorical groups on an independent variable via Kruskal–Wallis H stat.  \n",
        "\n",
        "Kruskal–Wallis stat (H) is:  \n",
        "\n",
        "$$\n",
        "H = \\frac{12}{N(N+1)} \\sum_{j=1}^k \\frac{R_j^2}{n_j} - 3(N+1)\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $H$ : Kruskal–Wallis test statistic  \n",
        "- $k$ : Number of groups  \n",
        "- $n_j$ : Sample size of group $j$  \n",
        "- $N = \\sum_{j=1}^k n_j$ : Total sample size  \n",
        "- $R_j$ : Sum of ranks for group $j$  \n",
        "\n",
        "And its interpretation is:  \n",
        "\n",
        "- $H \\approx 0$ → the groups are similar (no difference).  \n",
        "\n",
        "- Large $H$ value → at least one group distribution tends to differ strongly from the others (large difference).  \n",
        "\n",
        "It is Kruskal–Wallis H-stat of sample and to inference for population, hypothesis test must be used.  \n",
        "\n",
        "**1. Hypotheses**  \n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more different numerical & ordinal categorical groups on an independent variable **are not** significantly different.  \n",
        "- **Alternative hypothesis (H1):** The population differences between two or more different numerical & ordinal categorical groups on an independent variable **are** significantly different.    \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Kruskal–Wallis H Stat via Resampling**  \n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate Kruskal–Wallis H stat to get empirical probability distributions, not theoretical distributions like t-distribution.  \n",
        "\n",
        "Randomly shuffle the group labels across all observations. This simulates the null hypothesis H0, where no group differences exist.  \n",
        "\n",
        "For each permutation $j$, compute a new Kruskal–Wallis H stat:  \n",
        "\n",
        "$$\n",
        "H_{\\text{perm}}^{(j)} = \\text{KruskalWallis}(X^{(j)}_1, X^{(j)}_2, \\dots, X^{(j)}_k)\n",
        "$$  \n",
        "\n",
        "Repeat this process N times (e.g., 10,000) to generate the null distribution of H under H0.  \n",
        "\n",
        "**3. Kruskal–Wallis H Stat to P-Value**  \n",
        "\n",
        "- **Upper-tailed only (since $H \\ge 0$):**  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } H_{\\text{perm}}^{(j)} \\ge H_{\\text{obs}}}{N}\n",
        "$$  \n",
        "\n",
        "**4. P-Value vs $\\alpha$**  \n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01.  "
      ],
      "metadata": {
        "id": "q6MH4ME8QLYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scheirer–Ray–Hare (SRH) Test For Two-Way ANOVA Test"
      ],
      "metadata": {
        "id": "pJNKQJ1CH6VG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different numerical & ordinal categorical groups on two different independent variables via Scheirer–Ray–Hare H stat.  \n",
        "\n",
        "Scheirer–Ray–Hare stat (H) is:\n",
        "\n",
        "$$\n",
        "H = \\frac{12}{N(N+1)} \\sum_{j=1}^{k} \\frac{R_j^2}{n_j} - 3(N+1)\n",
        "$$  \n",
        "\n",
        "**Where:**  \n",
        "- $H$ : Scheirer–Ray–Hare test statistic for each factor or interaction  \n",
        "- $k$ : Number of levels for the factor or interaction  \n",
        "- $n_j$ : Sample size for level $j$  \n",
        "- $N = \\sum_{j=1}^{k} n_j$ : Total sample size  \n",
        "- $R_j$ : Sum of ranks for level $j$  \n",
        "\n",
        "And its interpretation is:  \n",
        "\n",
        "- $H \\approx 0$ → the groups/levels are similar (no difference).  \n",
        "- Large $H$ value → at least one group/level distribution tends to differ strongly from the others (large difference).  \n",
        "\n",
        "It is Scheirer–Ray–Hare H-stat of sample and to inference for population, hypothesis test must be used.  \n",
        "\n",
        "**1. Hypotheses**  \n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more different numerical & ordinal categorical groups on two different independent variables **are not** significantly different.  \n",
        "- **Alternative hypothesis (H1):** The population differences between two or more different numerical & ordinal categorical groups on two different independent variables **are** significantly different.  \n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.  \n",
        "\n",
        "**2. Scheirer–Ray–Hare H Stat via Resampling**  \n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate H stats to get empirical probability distributions, not theoretical distributions like t-distribution.\n",
        "\n",
        "Randomly shuffle the group labels across all observations. This simulates the null hypothesis H0, where no group differences exist.\n",
        "\n",
        "For each permutation $j$, compute new H stats for each factor and interaction:  \n",
        "\n",
        "$$\n",
        "H_{\\text{perm}}^{(j)} = \\text{ScheirerRayHare}(X^{(j)}_{\\text{levels}})\n",
        "$$  \n",
        "\n",
        "Repeat this process N times (e.g., 10,000) to generate the null distribution of H under H0.  \n",
        "\n",
        "**3. H Stat to P-Value**  \n",
        "\n",
        "- **Upper-tailed only (since $H \\ge 0$):**  \n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } H_{\\text{perm}}^{(j)} \\ge H_{\\text{obs}}}{N}\n",
        "$$  \n",
        "\n",
        "**4. P-Value vs $\\alpha$**  \n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01.  "
      ],
      "metadata": {
        "id": "irIvTNJLSIeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Friedman Test For One-Way Repeated Measures ANOVA Test"
      ],
      "metadata": {
        "id": "YogBXVplHxpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more repeated numerical & ordinal categorical measurements on the same group on an independent variable via Friedman (Q) stat.\n",
        "\n",
        "Friedman test stat (Q) is:\n",
        "\n",
        "$$\n",
        "Q = \\frac{12}{n k (k+1)} \\sum_{j=1}^{k} R_j^2 - 3 n (k+1)\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $Q$ : Friedman test stat\n",
        "- $n$ : Number of subjects\n",
        "- $k$ : Number of repeated measurements\n",
        "- $R_j$ : Sum of ranks for measurement $j$ (across subjects)\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$Q$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "Q \\approx 0 & \\text{Repeated measurements are similar (no difference)} \\\\\n",
        "\\text{Large } Q & \\text{At least one measurement tends to differ strongly from others (large difference)} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is Friedman Q-stat of sample and to infer for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more repeated numerical & ordinal categorical measurements on the same group on an independent variable **are not** significantly different.\n",
        "- **Alternative hypothesis (H1):** The population differences between two or more repeated numerical & ordinal categorical measurements on the same group on an independent variable **are** significantly different.\n",
        "\n",
        "To reject H0 (accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Friedman Q Stat via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate Friedman Q stat to get empirical probability distributions, not theoretical distributions like t-distribution.\n",
        "\n",
        "Also in repeated measures, block permutation must be used: each block retains its repeated measurements together. Permutation is applied across subjects to preserve the dependency structure.\n",
        "\n",
        "Randomly shuffle the group labels across all observations. This simulates the null hypothesis H0, where no group differences exist.\n",
        "\n",
        "For each permutation $j$, compute a new Friedman Q:\n",
        "\n",
        "$$\n",
        "Q_{\\text{perm}}^{(j)} = \\text{FriedmanTest}(X_1^{(j)}, X_2^{(j)}, \\dots, X_k^{(j)})\n",
        "$$\n",
        "\n",
        "Repeat N times (e.g., 10,000) to generate null distribution of $Q$ under H0.\n",
        "\n",
        "**3. Friedman Q Stat to P-Value**\n",
        "\n",
        "- Upper-tailed only (since $Q \\ge 0$):\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } Q_{\\text{perm}}^{(j)} \\ge Q_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "$\\alpha$ is generally 0.05–0.01."
      ],
      "metadata": {
        "id": "BDJ2-A7wMcju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aligned Rank Transform Test For Two-Way Repeated Measures ANOVA Test"
      ],
      "metadata": {
        "id": "PAtGC3R3H0wP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more repeated numerical & ordinal categorical groups on two different independent variables via $F_E$ stat.\n",
        "\n",
        "$F_E$ stat is:\n",
        "\n",
        "$$\n",
        "F_E = \\frac{MS_E}{MS_{\\text{Error}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $F_E$ : F-statistic for effect $E$ (main effect A, main effect B, or interaction $A \\times B$)\n",
        "- $MS_E$ : Mean square of aligned ranks for effect $E$\n",
        "- $MS_{\\text{Error}}$ : Mean square of error\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F_E$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F_E \\approx 0 & \\text{Aligned ranks of groups are similar (no effect)} \\\\\n",
        "\\text{Large } F_E & \\text{At least one group differs strongly (significant effect)} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is an $F_E$ stat of sample and to infer for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more repeated numerical & ordinal categorical groups on two different independent variables **are not** significantly different.\n",
        "- **Alternative hypothesis (H1):** The population differences between two or more repeated numerical & ordinal categorical groups on two different independent variables **are** significantly different.\n",
        "\n",
        "To reject H0 (accept H1), applying hypothesis test.\n",
        "\n",
        "**2. $F_E$ Stat via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate $F_E$ stat to get empirical probability distributions, not theoretical distributions like t-distribution.\n",
        "\n",
        "Also in repeated measures, block permutation must be used: each block retains its repeated measurements together. Permutation is applied across subjects to preserve the dependency structure.\n",
        "\n",
        "Randomly shuffle the group labels across all observations. This simulates the null hypothesis H0, where no group differences exist.\n",
        "\n",
        "For each permutation $j$, compute a new $F_E$:\n",
        "\n",
        "$$\n",
        "F_{\\text{perm}}^{(j)} = \\text{ART-ANOVA}(X^{(j)})\n",
        "$$\n",
        "\n",
        "Repeat N times (e.g., 10,000) to generate null distribution of $F_E$ under H0.\n",
        "\n",
        "**3. $F_E$ Stat to P-Value**\n",
        "\n",
        "- Upper-tailed only (since $F \\ge 0$):\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } F_{\\text{perm}}^{(j)} \\ge F_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "$\\alpha$ is generally 0.05–0.01."
      ],
      "metadata": {
        "id": "Zn1DZM6DPj4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Way PERMANOVA Test For One-Way MANOVA Test"
      ],
      "metadata": {
        "id": "8ZmaMchOH-Ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different numerical & ordinal categorical groups on an independent variable & multiple dependent variables via PERMANOVA F-stat.\n",
        "\n",
        "PERMANOVA F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{SS}_{\\text{between}} / (k-1)}{\\text{SS}_{\\text{within}} / (N-k)}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{SS}_{\\text{between}}$: Sum of squares between groups (based on distance matrix)  \n",
        "- $\\text{SS}_{\\text{within}}$: Sum of squares within groups (based on distance matrix)  \n",
        "- $k$: Number of groups  \n",
        "- $N$: Total sample size  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No difference between groups} \\\\\n",
        "F > 1 & \\text{Greater differences between groups} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is a PERMANOVA F-stat of sample and to infer for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more different numerical & ordinal categorical groups on an independent variable & multiple dependent variables **are not** significantly different.  \n",
        "- **Alternative hypothesis (H1):** The population differences between two or more different numerical & ordinal categorical groups on an independent variable & multiple dependent variables **are** significantly different.   \n",
        "\n",
        "To reject H0 (accept H1), applying hypothesis test.\n",
        "\n",
        "**2. PERMANOVA F Stat via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate PERMANOVA F stat to get empirical probability distributions, not theoretical distributions like t-distribution.\n",
        "\n",
        "Randomly shuffle the group labels across all observations. This simulates the null hypothesis H0, where no group differences exist.\n",
        "\n",
        "For each permutation $j$, compute a new PERMANOVA F:\n",
        "\n",
        "$$\n",
        "F_{\\text{perm}}^{(j)} = \\text{PERMANOVA}(X^{(j)})\n",
        "$$\n",
        "\n",
        "Repeat N times (e.g., 10,000) to generate null distribution of $F$ under H0.\n",
        "\n",
        "**3. PERMANOVA F Stat to P-Value**\n",
        "\n",
        "- Upper-tailed only (since $F \\ge 0$):\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } F_{\\text{perm}}^{(j)} \\ge F_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "-JrixtRrRv3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Two-Way PERMANOVA Test For Two-Way MANOVA Test"
      ],
      "metadata": {
        "id": "hqINOwPZRNIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more different numerical & ordinal categorical groups on two independent variables & multiple dependent variables via Two-Way PERMANOVA F-stat.\n",
        "\n",
        "Two-Way PERMANOVA F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{SS}_{\\text{effect}} / df_{\\text{effect}}}{\\text{SS}_{\\text{residual}} / df_{\\text{residual}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $\\text{SS}_{\\text{effect}}$: Sum of squares for the tested factor (Factor A, Factor B, or interaction A×B, based on distance matrix)  \n",
        "- $\\text{SS}_{\\text{residual}}$: Sum of squares of residuals (within-group variation, based on distance matrix)  \n",
        "- $df_{\\text{effect}}$: Degrees of freedom of the tested factor  \n",
        "- $df_{\\text{residual}}$: Degrees of freedom of residuals  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$F$ value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No effect of factor or interaction} \\\\\n",
        "F > 1 & \\text{Greater effect of factor or interaction} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is a Two-Way PERMANOVA F-stat of sample and to infer for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more different numerical & ordinal categorical groups on two independent variables & multiple dependent variables **are not** significantly different.  \n",
        "- **Alternative hypothesis (H1):** The population differences between two or more different numerical & ordinal categorical groups on two independent variables & multiple dependent variables **are** significantly different.  \n",
        "\n",
        "To reject H0 (accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Two-Way PERMANOVA F Stat via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate Two-Way PERMANOVA F stat to get empirical probability distributions, not theoretical distributions like t-distribution.\n",
        "\n",
        "Randomly shuffle the group labels across all observations. This simulates the null hypothesis H0, where no group differences exist.\n",
        "\n",
        "For each permutation $j$, compute a new PERMANOVA F:\n",
        "\n",
        "$$\n",
        "F_{\\text{perm}}^{(j)} = \\text{PERMANOVA}(X^{(j)})\n",
        "$$\n",
        "\n",
        "Repeat N times (e.g., 10,000) to generate null distribution of $F$ under H0.\n",
        "\n",
        "**3. Two-Way PERMANOVA F Stat to P-Value**\n",
        "\n",
        "- Upper-tailed only (since $F \\ge 0$):\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } F_{\\text{perm}}^{(j)} \\ge F_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:  \n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$  \n",
        "\n",
        "Otherwise, fail to reject H0.  \n",
        "\n",
        "Here, $\\alpha$ is generally assumed as 0.05–0.01."
      ],
      "metadata": {
        "id": "WEz2MAvoTWc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-Way Repeated Measures PERMANOVA Test For One-Way Repeated Measures MANOVA Test"
      ],
      "metadata": {
        "id": "tvFChot7WnG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more repeated numerical & ordinal categorical groups on an independent variable & multiple dependent variables via F-stat.\n",
        "\n",
        "F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{SS}_{\\text{between}} / \\text{df}_{\\text{between}}}{\\text{SS}_{\\text{within}} / \\text{df}_{\\text{within}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $F$ : PERMANOVA F-stat\n",
        "- $\\text{SS}_{\\text{between}}$ : Sum of squares between repeated factor levels (based on multiple dependent variables)\n",
        "- $\\text{SS}_{\\text{within}}$ : Sum of squares within repeated factor levels\n",
        "- $\\text{df}_{\\text{between}}$ : Degrees of freedom between factor levels ($k-1$, $k$ = number of repeated levels)\n",
        "- $\\text{df}_{\\text{within}}$ : Degrees of freedom within ($N-k$, $N$ = total observations)\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{F value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{Repeated multivariate measurements are similar (no difference)} \\\\\n",
        "F > 1 & \\text{At least one measurement tends to differ strongly from others (large difference)} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is F-stat of sample and to infer for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more repeated numerical & ordinal categorical groups on an independent variable & multiple dependent variables **are not** significantly different.\n",
        "- **Alternative hypothesis (H1):** The population differences between two or more repeated numerical & ordinal categorical groups on an independent variable & multiple dependent variables **are** significantly different.\n",
        "\n",
        "To reject H0 (accept H1), applying hypothesis test.\n",
        "\n",
        "**2. F-stat via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate F-stat to get empirical probability distributions, not only theoretical distributions like t-distributions.\n",
        "\n",
        "Also in repeated measures, block permutation must be used: each block retains its repeated measurements together. Permutation is applied across subjects to preserve the dependency structure.\n",
        "\n",
        "Randomly shuffle the condition labels across all observations. This simulates the null hypothesis H0, where no group differences exist.\n",
        "\n",
        "For each permutation $j$, compute a new F-stat:\n",
        "\n",
        "$$\n",
        "F_{\\text{perm}}^{(j)} = \\frac{\\text{SS}_{\\text{between}}^{(j)} / \\text{df}_{\\text{between}}}{\\text{SS}_{\\text{within}}^{(j)} / \\text{df}_{\\text{within}}}\n",
        "$$\n",
        "\n",
        "Repeat N times (e.g., 10,000) to generate null distribution of F-stat under H0.\n",
        "\n",
        "**3. F-Stat to P-Value**\n",
        "\n",
        "- Upper-tailed test (since larger F indicates stronger effect):\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } F_{\\text{perm}}^{(j)} \\ge F_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "$\\alpha$ is generally 0.05–0.01."
      ],
      "metadata": {
        "id": "uNe6kTsFWezw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Two-Way Repeated Measures PERMANOVA Test For Two-Way Repeated Measures MANOVA Test"
      ],
      "metadata": {
        "id": "hydyVWRMYttP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there are differences between two or more repeated numerical & ordinal categorical groups on two independent variables & multiple dependent variables via F-stat.\n",
        "\n",
        "F-stat is:\n",
        "\n",
        "$$\n",
        "F = \\frac{\\text{SS}_{\\text{effect}} / \\text{df}_{\\text{effect}}}{\\text{SS}_{\\text{residual}} / \\text{df}_{\\text{residual}}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $F$ : PERMANOVA F-stat\n",
        "- $\\text{SS}_{\\text{effect}}$ : Sum of squares for the tested factor (Factor A, Factor B, or interaction A×B, based on distance matrix)\n",
        "- $\\text{SS}_{\\text{residual}}$ : Sum of squares of residuals (within-group variation, based on distance matrix)\n",
        "- $\\text{df}_{\\text{effect}}$ : Degrees of freedom of the tested factor\n",
        "- $\\text{df}_{\\text{residual}}$ : Degrees of freedom of residuals\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{F value} & \\textbf{Difference} \\\\\n",
        "\\hline\n",
        "F \\approx 1 & \\text{No effect of factor or interaction (groups are similar)} \\\\\n",
        "F > 1 & \\text{Greater effect of factor or interaction (groups differ)} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is F-stat of sample and to infer for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "- **Null hypothesis (H0):** The population differences between two or more repeated numerical & ordinal categorical groups on two independent variables & multiple dependent variables **are not** significantly different.\n",
        "- **Alternative hypothesis (H1):** The population differences between two or more repeated numerical & ordinal categorical groups on two independent variables & multiple dependent variables **are** significantly different.\n",
        "\n",
        "To reject H0 (accept H1), applying hypothesis test.\n",
        "\n",
        "**2. F-stat via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap, can be used to recalculate F-stat to get empirical probability distributions, not only theoretical distributions like t-distributions.\n",
        "\n",
        "Also in repeated measures, block permutation must be used: each block retains its repeated measurements together. Permutation is applied across subjects to preserve the dependency structure.\n",
        "\n",
        "Randomly shuffle the condition labels across all observations. This simulates the null hypothesis H0, where no group differences exist.\n",
        "\n",
        "For each permutation $j$, compute a new F-stat:\n",
        "\n",
        "$$\n",
        "F_{\\text{perm}}^{(j)} = \\frac{\\text{SS}_{\\text{effect}}^{(j)} / \\text{df}_{\\text{effect}}}{\\text{SS}_{\\text{residual}}^{(j)} / \\text{df}_{\\text{residual}}}\n",
        "$$\n",
        "\n",
        "Repeat N times (e.g., 10,000) to generate null distribution of F-stat under H0.\n",
        "\n",
        "**3. F-stat to P-Value**\n",
        "\n",
        "- Upper-tailed only (since $F \\ge 0$):\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } F_{\\text{perm}}^{(j)} \\ge F_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "$\\alpha$ is generally 0.05–0.01."
      ],
      "metadata": {
        "id": "tNmiQVTNYu9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Parametric Test For Nominal Categorical Inter-Group"
      ],
      "metadata": {
        "id": "utRlYNxyIBMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cramer’s V With Chi-Square Homogeneity Test"
      ],
      "metadata": {
        "id": "zxGW6bU6IHWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a difference between two nominal categorical groups via Cramer’s V coefficient.\n",
        "\n",
        "Cramer’s V coefficient is:\n",
        "\n",
        "$$\n",
        "V = \\sqrt{\\frac{\\chi^2}{n \\cdot (k-1)}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $V$: Cramér's V coefficient\n",
        "- $\\chi^2$: Chi-square homogeneity test stat\n",
        "- $n$: Total number of observations  \n",
        "- $r$: Number of rows in the contingency table  \n",
        "- $c$: Number of columns in the contingency table  \n",
        "- $k = \\min(r, c)$: The smaller of the number of rows or columns  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$V$ value} & \\textbf{Difference strength} \\\\\n",
        "\\hline\n",
        "V = 0 & \\text{No difference} \\\\\n",
        "0 < V < 0.1 & \\text{Negligible difference} \\\\\n",
        "0.1 \\le V < 0.3 & \\text{Weak difference} \\\\\n",
        "0.3 \\le V < 0.5 & \\text{Moderate difference} \\\\\n",
        "V \\ge 0.5 & \\text{Strong difference} \\\\\n",
        "\\end{array}\n",
        "\n",
        "As is seen, Cramér's V measures only the strength of difference and does not provide information about direction like positive or negative because of that categorical variables do not have the concept of a “+” or “–” direction.\n",
        "\n",
        "It is Cramér's V coefficient of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "Here some confused points, chi-square test will be used because of that Cramér's V coefficient is based on chi-square and chi-square test is nonparametric while chi-square distribution is parametric.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The two categorical groups are **not different**.\n",
        "\n",
        "**Alternative hypothesis (H1):** The two categorical groups are **different**.\n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Chi-Square Homogeneity Test Stat**\n",
        "\n",
        "To standardize Cramér's V coefficient $V$ from sample to inference for population via X-stat because of V coefficient based on chi-square.\n",
        "\n",
        "The X-stat $\\chi^2$ is:\n",
        "\n",
        "$$\n",
        "\\chi^2 = \\sum_{i=1}^{r} \\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $O_{ij}$ : Observed frequency in cell $(i,j)$\n",
        "- $E_{ij}$ : Expected frequency in cell $(i,j)$\n",
        "- $r$ : Number of rows\n",
        "- $c$ : Number of columns\n",
        "\n",
        "Like chi-square distribution, every parametric distribution has a **degrees of freedom (df)** value, and for the X-stat, that is, the X-distribution, **df = (r - 1)(c - 1)** where r means number of rows & c means number of columns.\n",
        "\n",
        "**3. X-Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Under H0, the X-stat follows X-distribution and the probability density function (PDF) is:\n",
        "$$\n",
        "f_{\\chi^2}(X^2; df) =\n",
        "\\dfrac{1}{2^{df/2}\\Gamma(df/2)} \\, (X^2)^{\\frac{df}{2}-1} e^{-X^2/2}, \\quad X^2 > 0\n",
        "$$\n",
        "\n",
        "To integrate PDF as the cumulative distribution function (CDF) is:\n",
        "$$\n",
        "F_{\\chi^2}(X^2; df) = \\int_{0}^{X^2} f_{\\chi^2}(t; df) \\, dt\n",
        "$$\n",
        "\n",
        "**4. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p\\text = P(\\chi^2_{df} \\ge X^2) = 1 - F_{\\chi^2}(X^2; df)\n",
        "$$\n",
        "\n",
        "As is seen, the chi-square distribution is one-sided because of that X-stat is based on squared differences, so it cannot take negative values. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a relationship and the lower-tailed test logic is not meaningful for chi-square.\n",
        "\n",
        "**5. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "Here, $\\alpha$ is theoretically assumed as 0.05-0.01 generally."
      ],
      "metadata": {
        "id": "x50ra3_HH27T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTER-VARIABLE ANALYSIS"
      ],
      "metadata": {
        "id": "N7ZCgw_VN7E7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametric Test For Continuous Numerical Inter-Variables"
      ],
      "metadata": {
        "id": "-OzusB5CImtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pearson Correlation Test"
      ],
      "metadata": {
        "id": "tyY4SKfsIuW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a relationship between two continuous numerical variables via Pearson correlation coefficient.\n",
        "\n",
        "Pearson correlation coefficient is:  \n",
        "$$\n",
        "r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $r$: Pearson correlation coefficient  \n",
        "- $n$: Number of paired observations  \n",
        "- $x_i$: Value of variable $X$ at observation $i$  \n",
        "- $y_i$: Value of variable $Y$ at observation $i$  \n",
        "- $\\bar{x}$: Mean of variable $X$  \n",
        "- $\\bar{y}$: Mean of variable $Y$  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$r$ value} & \\textbf{Relationship} \\\\\n",
        "\\hline\n",
        "r = 1 & \\text{Perfect positive relationship} \\\\\n",
        "0.7 \\le r < 1 & \\text{Strong positive relationship} \\\\\n",
        "0.3 \\le r < 0.7 & \\text{Moderate positive relationship} \\\\\n",
        "0 < r < 0.3 & \\text{Weak positive relationship} \\\\\n",
        "r = 0 & \\text{No relationship} \\\\\n",
        "-0.3 < r < 0 & \\text{Weak negative relationship} \\\\\n",
        "-0.7 < r \\le -0.3 & \\text{Moderate negative relationship} \\\\\n",
        "-1 < r \\le -0.7 & \\text{Strong negative relationship} \\\\\n",
        "r = -1 & \\text{Perfect negative relationship} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is Pearson correlation of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population correlation coefficient **is not** significantly different from zero.\n",
        "\n",
        "**Alternative hypothesis (H1):** The population correlation coefficient **is** significantly different from zero.\n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Pearson Correlation Coefficient to Test Stat**\n",
        "\n",
        "To standardize Pearson correlation coefficient $r$ from sample to inference for population via t-stat.\n",
        "\n",
        "The t-stat derived from Pearson correlation coefficient $r$ is:\n",
        "$$\n",
        "t = \\frac{r \\sqrt{df}}{\\sqrt{1-r^2}}\n",
        "$$\n",
        "\n",
        "Like t-distribution, every parametric distribution has a **degrees of freedom (df)** value, and for the t-stat, that is, the t-distribution, **df = n − 2**.\n",
        "\n",
        "**3. Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Under H0, the t-stat follows t-distribution and the probability density function (PDF) is:\n",
        "$$\n",
        "f(t) = \\frac{\\Gamma\\left(\\frac{df+1}{2}\\right)}{\\sqrt{df \\pi}\\, \\Gamma\\left(\\frac{df}{2}\\right)} \\left(1 + \\frac{t^2}{df}\\right)^{-\\frac{df+1}{2}}\n",
        "$$\n",
        "\n",
        "To integrate PDF to t as the cumulative distribution function (CDF) is:\n",
        "$$\n",
        "F(t) = \\int_{-\\infty}^{t} f(u)\\,du\n",
        "$$\n",
        "\n",
        "**4. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "F(t) = P(T \\le t)\n",
        "$$\n",
        "\n",
        "It means the probability of values less than or equal to t.\n",
        "\n",
        "- **One-Tailed:**  \n",
        "  - Used when H0: parameter ≤ value, H1: parameter > value as **upper-tailed test** and the “extreme values” of interest are greater than t. Therefore, the p-value is:\n",
        "  $$\n",
        "  p = 1 - F(t)\n",
        "  $$  \n",
        "  - Used when H0: parameter ≥ value, H1: parameter < value as **lower-tailed test** and therefore, the p-value is directly:\n",
        "  $$\n",
        "  p = F(t)\n",
        "  $$\n",
        "\n",
        "- **Two-Tailed:**  \n",
        "\n",
        "  - Used when H0: parameter = value, H1: parameter ≠ value (i.e., \"different\") and to cover extreme values in both the upper and lower tails by using absolute value of t and formula multiplication by 2. Therefore, the p-value is:\n",
        "  $$\n",
        "  p = 2 \\cdot (1 - F(|t|))\n",
        "  $$  \n",
        "\n",
        "**5. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "Here, $\\alpha$ is theoretically assumed as 0.05-0.01 generally."
      ],
      "metadata": {
        "id": "d7qaV-LwI1cu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Parametric Test For Numerical & Ordinal Categorical Inter-Variables"
      ],
      "metadata": {
        "id": "axZ9U0_tI4pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spearman Rank Correlation Test"
      ],
      "metadata": {
        "id": "gA5U4im7I_ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a relationship between two numerical & ordinal categorical variables via Spearman rank correlation coefficient.\n",
        "\n",
        "Spearman rank correlation coefficient is:\n",
        "\n",
        "$$\n",
        "\\rho_s = 1 - \\frac{6 \\sum_{i=1}^{n} d_i^2}{n(n^2 - 1)}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "- $\\rho_s$ : Spearman rank correlation coefficient\n",
        "- $n$ : Number of paired observations\n",
        "- $d_i$ : Difference between the ranks of $x_i$ and $y_i$\n",
        "- $x_i, y_i$ : Values of variables $X$ and $Y$ at observation $i$ (converted to ranks)\n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$\\rho_s$ value} & \\textbf{Relationship} \\\\\n",
        "\\hline\n",
        "\\rho_s = 1 & \\text{Perfect positive relationship} \\\\\n",
        "0.7 \\le \\rho_s < 1 & \\text{Strong positive relationship} \\\\\n",
        "0.3 \\le \\rho_s < 0.7 & \\text{Moderate positive relationship} \\\\\n",
        "0 < \\rho_s < 0.3 & \\text{Weak positive relationship} \\\\\n",
        "\\rho_s = 0 & \\text{No relationship} \\\\\n",
        "-0.3 < \\rho_s < 0 & \\text{Weak negative relationship} \\\\\n",
        "-0.7 < \\rho_s \\le -0.3 & \\text{Moderate negative relationship} \\\\\n",
        "-1 < \\rho_s \\le -0.7 & \\text{Strong negative relationship} \\\\\n",
        "\\rho_s = -1 & \\text{Perfect negative relationship} \\\\\n",
        "\\end{array}\n",
        "\n",
        "It is Spearman correlation of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The population Spearman correlation coefficient **is not** significantly different from zero.\n",
        "\n",
        "**Alternative hypothesis (H1):** The population Spearman correlation coefficient **is** significantly different from zero.\n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Spearman Rank Correlation Coefficient via Resampling**\n",
        "\n",
        "Resampling simulations, such as permutation & bootstrap can be used to recalculate Spearman rank correlation coefficient to get empirical probability distributions, not theoretical distributions like t-distribution.\n",
        "\n",
        "Randomly shuffle the Y variable to break any existing relation between X and Y. This simulates the null hypothesis H0, where no relationship exists.\n",
        "\n",
        "For each permutation j, to compute a new Spearman rank correlation coefficient:\n",
        "\n",
        "$$\n",
        "\\rho_{\\text{perm}}^{(j)} = \\text{SpearmanRankCorr}(X, Y_{\\text{shuffled}}^{(j)})\n",
        "$$\n",
        "\n",
        "Repeat this process N times (e.g., 10,000) to generate the null distribution of correlation coefficients under H0.\n",
        "\n",
        "**3. Spearman Rank Correlation Coefficients to P-Value**\n",
        "\n",
        "- **One-Tailed:**  \n",
        "  - Used when H0: parameter ≤ value, H1: parameter > value as **upper-tailed test** and considered only extreme values greater than the observed correlation. Therefore, the p-value is:\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } \\rho_{\\text{perm}}^{(j)} \\ge \\rho_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "  - Used when H0: parameter ≥ value, H1: parameter < value as **lower-tailed test** and considered only extreme values smaller than the observed correlation. Therefore, the p-value is:\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } \\rho_{\\text{perm}}^{(j)} \\le \\rho_{\\text{obs}}}{N}\n",
        "$$\n",
        "\n",
        "- **Two-Tailed:**  \n",
        "\n",
        "  - Used when H0: parameter = value, H1: parameter ≠ value (i.e., \"different\") and compared the absolute values to account for extreme values in both directions. Therefore, the p-value is:\n",
        "\n",
        "$$\n",
        "p = \\frac{\\text{number of permutations where } |\\rho_{\\text{perm}}^{(j)}| \\ge |\\rho_{\\text{obs}}|}{N}\n",
        "$$\n",
        "\n",
        "**4. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "Here, $\\alpha$ is theoretically assumed as 0.05-0.01 generally."
      ],
      "metadata": {
        "id": "hP3pxCzUJFSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-Parametric Test For Nominal Categorical Inter-Variables"
      ],
      "metadata": {
        "id": "58T_GYiKJKgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cramer’s V With Chi-Square Independence Test"
      ],
      "metadata": {
        "id": "o8T5kCsiJMKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect whether there is a relationship between two nominal categorical variables via Cramer’s V coefficient.\n",
        "\n",
        "Cramer’s V coefficient is:\n",
        "\n",
        "$$\n",
        "V = \\sqrt{\\frac{\\chi^2}{n \\cdot (k-1)}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $V$: Cramér's V coefficient\n",
        "- $\\chi^2$: Chi-square independence test stat\n",
        "- $n$: Total number of observations  \n",
        "- $r$: Number of rows in the contingency table  \n",
        "- $c$: Number of columns in the contingency table  \n",
        "- $k = \\min(r, c)$: The smaller of the number of rows or columns  \n",
        "\n",
        "And its interpretation is:\n",
        "\n",
        "\\begin{array}{c|l}\n",
        "\\textbf{$V$ value} & \\textbf{Relationship strength} \\\\\n",
        "\\hline\n",
        "V = 0 & \\text{No relationship} \\\\\n",
        "0 < V < 0.1 & \\text{Negligible relationship} \\\\\n",
        "0.1 \\le V < 0.3 & \\text{Weak relationship} \\\\\n",
        "0.3 \\le V < 0.5 & \\text{Moderate relationship} \\\\\n",
        "V \\ge 0.5 & \\text{Strong relationship} \\\\\n",
        "\\end{array}\n",
        "\n",
        "As is seen, Cramér's V measures only the strength of relationship and does not provide information about direction like positive or negative because of that categorical variables do not have the concept of a “+” or “–” direction.\n",
        "\n",
        "It is Cramér's V coefficient of sample and to inference for population, hypothesis test must be used.\n",
        "\n",
        "Here some confused points, chi-square test will be used because of that Cramér's V coefficient is based on chi-square and chi-square test is nonparametric while chi-square distribution is parametric.\n",
        "\n",
        "**1. Hypotheses**\n",
        "\n",
        "**Null hypothesis (H0):** The two categorical variables are **not dependent**.\n",
        "\n",
        "**Alternative hypothesis (H1):** The two categorical variables are **dependent**.\n",
        "\n",
        "**To reject H0** (that is, to accept H1), applying hypothesis test.\n",
        "\n",
        "**2. Chi-Square Independence Test Stat**\n",
        "\n",
        "To standardize Cramér's V coefficient $V$ from sample to inference for population via X-stat because of V coefficient based on chi-square.\n",
        "\n",
        "The X-stat $\\chi^2$ is:\n",
        "\n",
        "$$\n",
        "\\chi^2 = \\sum_{i=1}^{r} \\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "\n",
        "- $O_{ij}$ : Observed frequency in cell $(i,j)$\n",
        "- $E_{ij}$ : Expected frequency in cell $(i,j)$\n",
        "- $r$ : Number of rows\n",
        "- $c$ : Number of columns\n",
        "\n",
        "Like chi-square distribution, every parametric distribution has a **degrees of freedom (df)** value, and for the X-stat, that is, the X-distribution, **df = (r - 1)(c - 1)** where r means number of rows & c means number of columns.\n",
        "\n",
        "**3. X-Test Stat to Distribution via PDF to CDF**\n",
        "\n",
        "Under H0, the X-stat follows X-distribution and the probability density function (PDF) is:\n",
        "$$\n",
        "f_{\\chi^2}(X^2; df) =\n",
        "\\dfrac{1}{2^{df/2}\\Gamma(df/2)} \\, (X^2)^{\\frac{df}{2}-1} e^{-X^2/2}, \\quad X^2 > 0\n",
        "$$\n",
        "\n",
        "To integrate PDF as the cumulative distribution function (CDF) is:\n",
        "$$\n",
        "F_{\\chi^2}(X^2; df) = \\int_{0}^{X^2} f_{\\chi^2}(t; df) \\, dt\n",
        "$$\n",
        "\n",
        "**4. CDF to P-Value**\n",
        "\n",
        "$$\n",
        "p\\text = P(\\chi^2_{df} \\ge X^2) = 1 - F_{\\chi^2}(X^2; df)\n",
        "$$\n",
        "\n",
        "As is seen, the chi-square distribution is one-sided because of that X-stat is based on squared differences, so it cannot take negative values. Therefore, the upper-tailed test logic is used: the larger the observed value, the higher the likelihood of a relationship and the lower-tailed test logic is not meaningful for chi-square.\n",
        "\n",
        "**5. P-Value vs $\\alpha$**\n",
        "\n",
        "To reject H0 if:\n",
        "$$\n",
        "p < \\alpha\n",
        "$$\n",
        "Otherwise, fail to reject H0.\n",
        "\n",
        "Here, $\\alpha$ is theoretically assumed as 0.05-0.01 generally."
      ],
      "metadata": {
        "id": "G0z_th-PN-tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFIRMATORY DATA ANALYSIS IN PYTHON"
      ],
      "metadata": {
        "id": "sSjb354HJbAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTER-GROUP ANALYSIS IN PYTHON"
      ],
      "metadata": {
        "id": "uE86aluRa4CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOON"
      ],
      "metadata": {
        "id": "zX_uotKZGM8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTER-VARIABLE ANALYSIS IN PYTHON"
      ],
      "metadata": {
        "id": "GTl9jFjbGGs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOON"
      ],
      "metadata": {
        "id": "vkgzQIv6CNWK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}